<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>靺鞨笔记</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><li class="part-title">LeetCode</li><li class="chapter-item expanded "><a href="leetcode/algorithms.html"><strong aria-hidden="true">1.</strong> Algorithms</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="leetcode/algorithms/binary_search.html"><strong aria-hidden="true">1.1.</strong> Binary Search</a></li><li class="chapter-item expanded "><a href="leetcode/algorithms/delta_diff_array.html"><strong aria-hidden="true">1.2.</strong> Delta / Difference Array</a></li><li class="chapter-item expanded "><a href="leetcode/algorithms/dijkstra.html"><strong aria-hidden="true">1.3.</strong> Dijkstra</a></li><li class="chapter-item expanded "><a href="leetcode/algorithms/math.html"><strong aria-hidden="true">1.4.</strong> Math</a></li><li class="chapter-item expanded "><a href="leetcode/algorithms/prefix_sum.html"><strong aria-hidden="true">1.5.</strong> Prefix Sum</a></li></ol></li><li class="chapter-item expanded "><a href="leetcode/data_structure.html"><strong aria-hidden="true">2.</strong> Data Structure</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="leetcode/data_structure/segment_tree.html"><strong aria-hidden="true">2.1.</strong> Segment Tree</a></li><li class="chapter-item expanded "><a href="leetcode/data_structure/trie.html"><strong aria-hidden="true">2.2.</strong> Trie</a></li></ol></li><li class="chapter-item expanded "><a href="leetcode/rust.html"><strong aria-hidden="true">3.</strong> Rust</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="leetcode/rust/btreemap.html"><strong aria-hidden="true">3.1.</strong> BTreeMap</a></li><li class="chapter-item expanded "><a href="leetcode/rust/linkedlist.html"><strong aria-hidden="true">3.2.</strong> LinkedList</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">System Design</li><li class="chapter-item expanded "><a href="system_design/system_design.html"><strong aria-hidden="true">4.</strong> Interview Strategy</a></li><li class="chapter-item expanded "><a href="system_design/fundamental.html"><strong aria-hidden="true">5.</strong> Fundamental</a></li><li><ol class="section"><li class="chapter-item expanded "><a href=".system_design/../system_design/fundamentals/algorithms.html"><strong aria-hidden="true">5.1.</strong> Algorithms</a></li><li class="chapter-item expanded "><a href="system_design/fundamentals/consistency.html"><strong aria-hidden="true">5.2.</strong> Consistency</a></li><li class="chapter-item expanded "><a href="system_design/fundamentals/technologies.html"><strong aria-hidden="true">5.3.</strong> Technologies</a></li><li class="chapter-item expanded "><a href="system_design/fundamentals/four_distributed_system_architectural_patterns.html"><strong aria-hidden="true">5.4.</strong> Four Distributed System Architectural Patterns</a></li><li class="chapter-item expanded "><a href="system_design/fundamentals/api_design.html"><strong aria-hidden="true">5.5.</strong> API Design: GraphQL vs. gRPC vs. REST</a></li><li class="chapter-item expanded "><a href="system_design/fundamentals/websocket_vs_http2.html"><strong aria-hidden="true">5.6.</strong> Websocket vs. HTTP/2</a></li></ol></li><li class="chapter-item expanded "><a href="system_design/examples.html"><strong aria-hidden="true">6.</strong> Examples</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="system_design/examples/netflix_zuul.html"><strong aria-hidden="true">6.1.</strong> Netflix Zuul</a></li><li class="chapter-item expanded "><a href="system_design/examples/aws_fargate.html"><strong aria-hidden="true">6.2.</strong> AWS Fargate</a></li></ol></li><li class="chapter-item expanded "><a href="system_design/questions.html"><strong aria-hidden="true">7.</strong> Questions</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="system_design/questions/design_key_value_store.html"><strong aria-hidden="true">7.1.</strong> Design Key Value Store</a></li><li class="chapter-item expanded "><a href="system_design/questions/design_rate_limiter.html"><strong aria-hidden="true">7.2.</strong> Design Rate Limiter</a></li><li class="chapter-item expanded "><a href="system_design/questions/design_distributed_cache.html"><strong aria-hidden="true">7.3.</strong> Design Distributed Cache</a></li><li class="chapter-item expanded "><a href="system_design/questions/design_payment_network.html"><strong aria-hidden="true">7.4.</strong> Design Payment Network</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Career</li><li class="chapter-item expanded "><a href="career/career.html"><strong aria-hidden="true">8.</strong> Career</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">靺鞨笔记</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="algorithms"><a class="header" href="#algorithms">algorithms</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="binary-search"><a class="header" href="#binary-search">Binary Search</a></h1>
<h2 id="template"><a class="header" href="#template">Template</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn check(mid: i32) -&gt; bool {
    todo!()
}

fn binary_search() -&gt; i32 {
    let mut left = 0;
    let mut right = i32::MAX;

    while left &lt; right {
        let mid = left + (right - left) / 2;
        if check(mid) {
            left = mid;
        } else {
            right = mid - 1;
        }
    }

    left
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="key-approaches"><a class="header" href="#key-approaches">Key Approaches</a></h2>
<p><em>Credit to @Lee215</em></p>
<ol>
<li>
<p>use <code>left &lt; right</code> or <code>left &lt;= right</code></p>
<p>to make the binary search process easier, we do not handle the <code>left == right</code> case in the loop. Instead, we will try to make the least <code>left</code> index to point to the correct answer that we are looking for.</p>
</li>
<li>
<p>use <code>mid = left + (right - left) / 2</code> or <code>mid = left + (right - left + 1) / 2</code></p>
<ul>
<li>use <code>mid = left + (right - left) / 2</code> to find the index of the first valid element</li>
<li>use <code>mid = left + (right - left + 1) / 2</code> to find the index of the last valid element</li>
</ul>
</li>
</ol>
<h2 id="search-for-the-first-index-of-the-valid-value"><a class="header" href="#search-for-the-first-index-of-the-valid-value">Search for the first index of the valid value</a></h2>
<pre><code>  0   1   2   3   4   5   6   7   8   9
 --- --- --- --- --- --- --- --- --- ---
| 0 | 0 | 1 | 1 | 2 | 2 | 2 | 3 | 3 | 3 |
 --- --- --- --- --- --- --- --- --- ---
                  ^
                  |
                target

                  ^   ^   ^   ^   ^   ^
                  |   |   |   |   |   |
                          valid
</code></pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">fn main() {
</span><span class="boring">   let list = vec![0, 0, 1, 1, 2, 2, 2, 3, 3, 3];
</span><span class="boring">   let k = 2;
</span><span class="boring">   let res = binary_search_first_valid(list, k);
</span><span class="boring">   println!(&quot;Result: {:?}&quot;, res);
</span><span class="boring">}
</span><span class="boring">
</span>fn binary_search_first_valid(list: Vec&lt;i32&gt;, target: i32) -&gt; usize {
    fn check(list: &amp;Vec&lt;i32&gt;, mid: usize, target: i32) -&gt; bool {
        list[mid] &gt;= target
    }

    let mut left = 0;
    let mut right = list.len();

    while left &lt; right {
        let mid = left + (right - left) / 2;
        if check(&amp;list, mid, target) {
            right = mid;
        } else {
            left = mid + 1;
        }
    }

    left
}
</code></pre></pre>
<h2 id="search-for-the-last-index-of-the-valid-value"><a class="header" href="#search-for-the-last-index-of-the-valid-value">Search for the last index of the valid value</a></h2>
<pre><code>  0   1   2   3   4   5   6   7   8   9
 --- --- --- --- --- --- --- --- --- ---
| 0 | 0 | 1 | 1 | 2 | 2 | 2 | 3 | 3 | 3 |
 --- --- --- --- --- --- --- --- --- ---
                          ^
                          |
                        target
  ^   ^   ^   ^   ^   ^   ^
  |   |   |   |   |   |   |
            valid
</code></pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">fn main() {
</span><span class="boring">    let list = vec![0, 0, 1, 1, 2, 2, 2, 3, 3 ,3];
</span><span class="boring">    let k = 2;
</span><span class="boring">    let res = binary_search_last_valid(list, k);
</span><span class="boring">    println!(&quot;Result: {:?}&quot;, res);
</span><span class="boring">}
</span><span class="boring">
</span>fn binary_search_last_valid(list: Vec&lt;i32&gt;, target: i32) -&gt; usize {
    fn check(list: &amp;Vec&lt;i32&gt;, mid: usize, target: i32) -&gt; bool {
        list[mid] &lt;= target
    }

    let mut left = 0;
    let mut right = list.len();

    while left &lt; right {
        let mid = left + (right - left + 1) / 2;
        if check(&amp;list, mid, target) {
            left = mid;
        } else {
            right = mid - 1;
        }
    }

    left
}
</code></pre></pre>
<h2 id="search-for-the-exact-index-of-a-valid-element"><a class="header" href="#search-for-the-exact-index-of-a-valid-element">Search for the exact index of a valid element</a></h2>
<pre><code>  0   1   2   3   4   5   6   7   8   9
 --- --- --- --- --- --- --- --- --- ---
| 0 | 0 | 1 | 1 | 1 | 1 | 2 | 3 | 3 | 3 |
 --- --- --- --- --- --- --- --- --- ---
                          ^
                          |
                        target
</code></pre>
<p>The first approach is to use the rust built-in binary search method of a <code>Vec</code></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let list = vec![0, 0, 1, 1, 1, 1, 2, 3, 3 ,3];
let target = 2;
let res = list.binary_search(&amp;target);
println!(&quot;Result: {:?}&quot;, res); // Ok(6)
<span class="boring">}
</span></code></pre></pre>
<p>Another benefit is the built in binary search method will also yield the location where the given value should be inserted to keep the <code>Vec</code> in the sorted order.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let list = vec![0, 0, 1, 1, 1, 1, 3, 3, 3 ,3];
let target = 2;
let res = list.binary_search(&amp;target);
println!(&quot;Result: {:?}&quot;, res); // Err(6)
<span class="boring">}
</span></code></pre></pre>
<p>Let's see how can we adapt the &quot;Search for the first index of the valid value&quot; to do the same as the above built-in binary search function.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">fn main() {
</span><span class="boring">   let list = vec![0, 0, 1, 1, 2, 3, 3, 3, 3, 3];
</span><span class="boring">   let k = 2;
</span><span class="boring">   let res = binary_search(list, k);
</span><span class="boring">   println!(&quot;Search for 2 in the list [0, 0, 1, 1, 2, 3, 3, 3, 3, 3]&quot;);
</span><span class="boring">   println!(&quot;Result: {:?}&quot;, res);
</span><span class="boring">
</span><span class="boring">   let list = vec![0, 0, 1, 1, 2, 3, 3, 3, 3, 3];
</span><span class="boring">   let k = 4;
</span><span class="boring">   let res = binary_search(list, k);
</span><span class="boring">   println!(&quot;Search for 4 in the list [0, 0, 1, 1, 2, 3, 3, 3, 3, 3]&quot;);
</span><span class="boring">   println!(&quot;Result: {:?}&quot;, res);
</span><span class="boring">}
</span><span class="boring">
</span>fn binary_search(list: Vec&lt;i32&gt;, target: i32) -&gt; Result&lt;usize, usize&gt; {
    fn check(list: &amp;Vec&lt;i32&gt;, mid: usize, target: i32) -&gt; bool {
        list[mid] &gt;= target
    }

    let mut left = 0;
    let mut right = list.len();

    while left &lt; right {
        let mid = left + (right - left) / 2;
        if check(&amp;list, mid, target) {
            right = mid;
        } else {
            left = mid + 1;
        }
    }

    if left &lt; list.len() {
        Ok(left)
    } else {
        Err(left)
    }
}
</code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="delta--difference-array"><a class="header" href="#delta--difference-array">Delta / Difference Array</a></h1>
<p>The idea of prefix sum is to construct an array that record the changes happened at each index. This is often useful when deal with scheduling issue and when working with a time series of events</p>
<pre><code>Schedule - bookings
 |-----------------------|  [0, 6]
         |-----------|  [2, 5]
     |-------|  [1, 3]
         |-------------------|  [2, 7]
 +---+---+---+---+---+---+---+---+
 0   1   2   3   4   5   6   7   8

Delta / Diff Array
 1   1   2   0  -1   0  -1  -1  -1
 +---+---+---+---+---+---+---+---+
 0   1   2   3   4   5   6   7   8

Number of booking at each timestamp
 1   2   4   4   3   3   2   1   0
 +---+---+---+---+---+---+---+---+
 0   1   2   3   4   5   6   7   8
</code></pre>
<p><strong>Example</strong></p>
<p>In the graph above we have the following 4 time slot <code>[0, 6], [2, 5], [1, 3], [4, 7]</code>, let's say that we want to find out at each timestamp how many booking are there on the schedule. How can we figure it out?</p>
<p><strong>Using a BTreeMap</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">use std::collections::BTreeMap;
</span><span class="boring">
</span>let schedule = vec![(0, 6), (2, 5), (1, 3), (4, 7)];
let mut delta: BTreeMap&lt;usize, i32&gt; = BTreeMap::new();

for (start, end) in schedule {
    *delta.entry(start).or_insert(0) += 1;
    *delta.entry(end + 1).or_insert(0) -= 1;
}

println!(&quot;delta - diff array: {:?}&quot;, delta);
<span class="boring">}
</span></code></pre></pre>
<p><strong>Using a Vec</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">use std::collections::BTreeMap;
</span><span class="boring">
</span>let schedule = vec![(0, 6), (2, 5), (1, 3), (4, 7)];
let mut delta = vec![0; 9];

for (start, end) in schedule {
    delta[start] += 1;
    delta[end + 1] -= 1;
}

let mut num_of_booking = vec![0; 9];
let mut curr_number_of_booking = 0;

for i in 0..9 {
    curr_number_of_booking += delta[i];
    num_of_booking[i] = curr_number_of_booking;
}

println!(&quot;delta - diff array: {:?}&quot;, delta);
println!(&quot;number of booking:  {:?}&quot;, num_of_booking);
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="dijkstra-f64"><a class="header" href="#dijkstra-f64">Dijkstra f64</a></h2>
<pre><pre class="playground"><code class="language-rust">use std::cmp::Ordering;
use std::collections::BinaryHeap;

#[derive(PartialEq, PartialOrd)]
struct Node {
    node: usize,
    prob: f64,
}

impl Eq for Node {}

impl Ord for Node {
    fn cmp(&amp;self, other: &amp;Self) -&gt; Ordering {
        // Max-heap
        self.prob
            .partial_cmp(&amp;other.prob)
            .unwrap()
            .then_with(|| self.node.cmp(&amp;other.node))
    }
}

struct Solution {}

impl Solution {
    pub fn max_probability(
        n: i32,
        edges: Vec&lt;Vec&lt;i32&gt;&gt;,
        succ_prob: Vec&lt;f64&gt;,
        start: i32,
        end: i32,
    ) -&gt; f64 {
        let n = n as usize;
        let start = start as usize;
        let end = end as usize;
        let graph = Self::convert_edge_list_to_adjacency_list(edges, succ_prob, n);

        // Dijkstra
        // Edges: E
        // Nodes/Vertices: V
        //
        // Time Complexity: O(E + V log V )
        // Space Complexity: O(V)
        let mut cost = vec![0.0; n];
        cost[start] = 1.0;

        let mut pq: BinaryHeap&lt;Node&gt; = BinaryHeap::new();
        pq.push(Node {
            node: start,
            prob: 1.0,
        });

        while let Some(node) = pq.pop() {
            for (next, edge_prob) in &amp;graph[node.node] {
                let prob = *edge_prob * node.prob;
                if prob &gt; cost[*next] {
                    cost[*next] = prob;
                    pq.push(Node { node: *next, prob })
                }
            }
        }

        cost[end]
    }

    /// Edges: E
    /// Nodes/Vertices: V
    ///
    /// Time Complexity: O(E)
    /// Space Complexity: O(V + E)
    fn convert_edge_list_to_adjacency_list(
        edges: Vec&lt;Vec&lt;i32&gt;&gt;,
        succ_prob: Vec&lt;f64&gt;,
        n: usize,
    ) -&gt; Vec&lt;Vec&lt;(usize, f64)&gt;&gt; {
        let mut graph: Vec&lt;Vec&lt;(usize, f64)&gt;&gt; = vec![vec![]; n];
        for i in 0..edges.len() {
            let u = edges[i][0] as usize;
            let v = edges[i][1] as usize;
            let prob = succ_prob[i];
            graph[u].push((v, prob));
            graph[v].push((u, prob));
        }
        graph
    }
}

fn main() {
    let n = 3;
    let edges = [[0, 1], [1, 2], [0, 2]];
    let edges: Vec&lt;Vec&lt;i32&gt;&gt; = edges.into_iter().map(|e| e.to_vec()).collect();
    let succ_prob = [0.5, 0.5, 0.2];
    let succ_prob: Vec&lt;f64&gt; = succ_prob.into_iter().collect();
    let start = 0;
    let end = 2;
    let res = Solution::max_probability(n, edges, succ_prob, start, end);
    println!(&quot;{:?}&quot;, res);
}

</code></pre></pre>
<h2 id="dijkstra-i64"><a class="header" href="#dijkstra-i64">Dijkstra i64</a></h2>
<pre><pre class="playground"><code class="language-rust">use std::{cmp::Ordering, collections::BinaryHeap};

#[derive(Eq, PartialEq)]
struct Node {
    index: usize,
    cost: i64,
}

impl Ord for Node {
    fn cmp(&amp;self, other: &amp;Self) -&gt; Ordering {
        // min-heap
        other
            .cost
            .cmp(&amp;self.cost)
            .then_with(|| self.index.cmp(&amp;other.index))
    }
}

impl PartialOrd for Node {
    fn partial_cmp(&amp;self, other: &amp;Self) -&gt; Option&lt;Ordering&gt; {
        Some(self.cmp(other))
    }
}

struct Solution {}

impl Solution {
    const MODULO: i64 = 10_0000_0007;

    /// Edges: E
    /// Nodes/Vertices: V
    ///
    /// Time Complexity: O(E)
    /// Space Complexity: O(V + E)
    fn convert_edge_list_to_adjacency_list(
        edges: Vec&lt;Vec&lt;i32&gt;&gt;,
        n: usize,
    ) -&gt; Vec&lt;Vec&lt;(usize, i64)&gt;&gt; {
        let mut graph: Vec&lt;Vec&lt;(usize, i64)&gt;&gt; = vec![vec![]; n];
        for edge in edges {
            let src = edge[0] as usize;
            let dst = edge[1] as usize;
            let cost = edge[2] as i64;
            graph[src].push((dst, cost));
            graph[dst].push((src, cost));
        }
        graph
    }

    pub fn count_paths(n: i32, roads: Vec&lt;Vec&lt;i32&gt;&gt;) -&gt; i32 {
        let n = n as usize;
        let graph: Vec&lt;Vec&lt;(usize, i64)&gt;&gt; = Self::convert_edge_list_to_adjacency_list(roads, n);
        let mut cost: Vec&lt;i64&gt; = vec![i64::MAX; n];
        let mut path_count: Vec&lt;i64&gt; = vec![0; n];

        // Dijkstra
        // Edges: E
        // Nodes/Vertices: V
        //
        // Time Complexity: O(E + V log V )
        // Space Complexity: O(V)
        let mut pq: BinaryHeap&lt;Node&gt; = BinaryHeap::new();
        path_count[0] = 1;
        cost[0] = 0;
        pq.push(Node { index: 0, cost: 0 });

        while let Some(node) = pq.pop() {
            for (next_index, next_cost) in &amp;graph[node.index] {
                if node.cost + *next_cost &gt; cost[*next_index] {
                    continue;
                } else if cost[*next_index] == node.cost + *next_cost {
                    path_count[*next_index] =
                        (path_count[*next_index] + path_count[node.index]) % Self::MODULO;
                } else {
                    cost[*next_index] = node.cost + *next_cost;
                    path_count[*next_index] = path_count[node.index];
                    pq.push(Node {
                        index: *next_index,
                        cost: node.cost + *next_cost,
                    });
                }
            }

            // println!(&quot;{:?} {:?} {:?}&quot;, node.index, node.cost, node.path);
            // println!(&quot;{:?}&quot;, cost);
            // println!(&quot;{:?}&quot;, path_count);
        }

        path_count[n - 1] as i32
    }
}

fn main() {
    let n = 7;
    let roads = [
        [0, 6, 7],
        [0, 1, 2],
        [1, 2, 3],
        [1, 3, 3],
        [6, 3, 3],
        [3, 5, 1],
        [6, 5, 1],
        [2, 5, 1],
        [0, 4, 5],
        [4, 6, 2],
    ];
    let roads = roads.into_iter().map(|r| r.to_vec()).collect();
    let res = Solution::count_paths(n, roads);
    println!(&quot;{:?}&quot;, res);
}

</code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="math"><a class="header" href="#math">Math</a></h1>
<h2 id="greatest-common-divisor"><a class="header" href="#greatest-common-divisor">Greatest Common Divisor</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">fn main() {
</span><span class="boring">    println!(&quot;gcd of 10 and 5  is {}&quot;, greatest_common_divisor(10, 5));
</span><span class="boring">    println!(&quot;gcd of 11 and 22 is {}&quot;, greatest_common_divisor(11, 22));
</span><span class="boring">    println!(&quot;gcd of 44 and 63  is {}&quot;, greatest_common_divisor(44, 63));
</span><span class="boring">    println!(&quot;gcd of 44 and 64  is {}&quot;, greatest_common_divisor(44, 64));
</span><span class="boring">}
</span>
fn greatest_common_divisor(a: i32, b: i32) -&gt; i32 {
    if b != 0 {
        greatest_common_divisor(b, a % b)
    } else {
        a
    }
}
</code></pre></pre>
<h2 id="least-common-multiple"><a class="header" href="#least-common-multiple">Least Common Multiple</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">fn main() {
</span><span class="boring">    println!(&quot;lcm of 10 and 5  is {}&quot;, least_common_multiple(10, 5));
</span><span class="boring">    println!(&quot;lcm of 11 and 22 is {}&quot;, least_common_multiple(11, 22));
</span><span class="boring">    println!(&quot;lcm of 44 and 63  is {}&quot;, least_common_multiple(44, 63));
</span><span class="boring">    println!(&quot;lcm of 44 and 64  is {}&quot;, least_common_multiple(44, 64));
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">fn greatest_common_divisor(a: i32, b: i32) -&gt; i32 {
</span><span class="boring">    if b != 0 {
</span><span class="boring">        greatest_common_divisor(b, a % b)
</span><span class="boring">    } else {
</span><span class="boring">        a
</span><span class="boring">    }
</span><span class="boring">}
</span><span class="boring">
</span>fn least_common_multiple(a: i32, b: i32) -&gt; i32 {
    a * b / greatest_common_divisor(a, b)
}
</code></pre></pre>
<h2 id="fraction-comparison--slope-comparison"><a class="header" href="#fraction-comparison--slope-comparison">Fraction Comparison / Slope Comparison</a></h2>
<p>When comparing <code>a/b</code> and <code>x/y</code> in computer science, we can use a floating point (<code>f64</code> in rust or <code>double</code> in java). Nevertheless, due to the limited precision of IEEE 754-1985 / IEEE 754-2008 floating point standard, directly checking <code>a / b == x / y</code> might not yield the correct result. Hence, we have two alternative approaches:</p>
<ol>
<li>
<p><strong>Cross Product</strong></p>
<p>Instead of checking <code>a / b == x / y</code>, we can check <code>a * y == x * b</code>.</p>
</li>
<li>
<p><strong>GDC Slope</strong></p>
<p>If <code>a / b</code> and <code>x / y</code> represent the same slope, then <code>a / gcd(a, b) == x / gcd(x, y)</code> and <code>b / gcd(a, b) == y / gcd(x, y)</code> must be true.</p>
</li>
</ol>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn gcd(a: i128, b: i128) -&gt; i128 {
</span><span class="boring">    if b != 0 { gcd(b, a % b) } else { a }
</span><span class="boring">}
</span><span class="boring">let (a, b) = (1, 1);
</span><span class="boring">let (x, y) = (999999999999999999, 1000000000000000000);
</span><span class="boring">
</span>println!(&quot;a: {}&quot;, a);
println!(&quot;b: {}&quot;, b);
println!(&quot;x: {}&quot;, x);
println!(&quot;y: {}&quot;, y);

let equal = a as f64 / b as f64 == x as f64 / y as f64;
let equal_cross_product = a * y == x * b;
let equal_gdc = a / gcd(a, b) == x / gcd(x, y) &amp;&amp; b / gcd(a, b) == y / gcd(x, y);

println!(&quot;Standard approach:      {}&quot;, equal);
println!(&quot;Cross product approach: {}&quot;, equal_cross_product);
println!(&quot;GDC approach:           {}&quot;, equal_gdc);
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="prefix-sum"><a class="header" href="#prefix-sum">Prefix Sum</a></h1>
<p>The idea of prefix sum is to construct an array that for each index <code>prefix_sum[index]</code> represent the total cumulative sum of all element between the first element to the element for the given index. This is an useful tool when there are a lot of operation of getting the sum of a sub-array of the inputting array.</p>
<pre><code>numbers
 ----- ----- ----- ----- ----- ----- -----
|  4  |  6  |  10 |  40 |  5  |  8  |  30 |
 ----- ----- ----- ----- ----- ----- -----
   0     1     2     3     4     5     6

prefix-sum (inclusive)
 ----- ----- ----- ----- ----- ----- -----
|  4  |  10 |  20 |  60 |  65 |  73 | 103 |
 ----- ----- ----- ----- ----- ----- -----
   0     1     2     3     4     5     6

prefix-sum (exclusive)
 ----- ----- ----- ----- ----- ----- ----- -----
|  0  |  4  |  10 |  20 |  60 |  65 |  73 | 103 |
 ----- ----- ----- ----- ----- ----- ----- -----
   0     1     2     3     4     5     6     7

</code></pre>
<p><strong>Variables</strong></p>
<ul>
<li><code>numbers</code> the input arrays that contains numbers with length of <code>n</code></li>
<li><code>prefix_sum</code> the prefix sum array</li>
</ul>
<p><strong>Two types of prefix sum</strong></p>
<ul>
<li>
<p>inclusive prefix sum</p>
<ul>
<li><code>prefix_sum[i] = prefix_sum[i - 1] + number[i]</code></li>
<li>The value <code>prefix_sum[i]</code> includes <code>number[i]</code> and all numbers comes before <code>number[i]</code></li>
</ul>
</li>
<li>
<p>exclusive prefix sum</p>
<ul>
<li><code>prefix_sum[i] = prefix_sum[i - 1] + number[i - 1]</code></li>
<li>The value <code>prefix_sum[i]</code> does not <code>number[i]</code> but includes all numbers comes before <code>number[i]</code></li>
</ul>
</li>
</ul>
<p>For the sake of simplicity and to avoid accessing numbers with native index, I always use the <strong>exclusive prefix sum</strong></p>
<p>How to build the prefix sum array:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let numbers = vec![4, 6, 10, 40, 5, 8, 30];
let mut prefix_sum = vec![0; numbers.len() + 1];

for i in 0..numbers.len() {
    prefix_sum[i + 1] = prefix_sum[i] + numbers[i];
}

println!{&quot;numbers:    {:?}&quot;, numbers};
println!{&quot;prefix_sum: {:?}&quot;, prefix_sum};
<span class="boring">}
</span></code></pre></pre>
<p>How to access the sum of all element with index <code>[i, j)</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">let prefix_sum = vec![0, 4, 10, 20, 60, 65, 73, 103];
</span>let (i, j) = (2, 5);
let sum = prefix_sum[j] - prefix_sum[i];

println!(&quot;sum of sub array [10, 40, 5]: {:?}&quot;, sum);
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="data-structure"><a class="header" href="#data-structure">Data Structure</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="segment-tree-range-sum"><a class="header" href="#segment-tree-range-sum">Segment Tree Range Sum</a></h1>
<pre><pre class="playground"><code class="language-rust">use std::{
    cmp::Ordering,
    collections::{BinaryHeap, HashMap, HashSet},
    fmt::{Binary, Debug},
};

fn main() {
    let vec = vec![1, 3, 5];

    let mut num_array = NumArray::new(vec);
    println!(&quot;{:?}&quot;, num_array.sum_range(0, 2));
    println!(&quot;{:?}&quot;, num_array.update(1, 2));
    println!(&quot;{:?}&quot;, num_array.sum_range(0, 2))
}

struct SegmentTreeNode&lt;'a, T&gt; {
    left_node: Option&lt;Box&lt;SegmentTreeNode&lt;'a, T&gt;&gt;&gt;,
    right_node: Option&lt;Box&lt;SegmentTreeNode&lt;'a, T&gt;&gt;&gt;,
    left_index: usize,
    right_index: usize,
    info: T,
    operation: &amp;'a dyn Fn(&amp;T, &amp;T) -&gt; T,
}

impl&lt;'a, T&gt; Debug for SegmentTreeNode&lt;'a, T&gt;
where
    T: Debug,
{
    fn fmt(&amp;self, f: &amp;mut std::fmt::Formatter&lt;'_&gt;) -&gt; std::fmt::Result {
        f.debug_struct(&quot;SegmentTreeNode&quot;)
            .field(&quot;left_node&quot;, &amp;self.left_node)
            .field(&quot;right_node&quot;, &amp;self.right_node)
            .field(&quot;left_index&quot;, &amp;self.left_index)
            .field(&quot;right_index&quot;, &amp;self.right_index)
            .field(&quot;info&quot;, &amp;self.info)
            .finish()
    }
}

impl&lt;'a, T&gt; SegmentTreeNode&lt;'a, T&gt;
where
    T: Copy + Debug,
{
    fn new_from_vec(vec: Vec&lt;T&gt;, operation: &amp;'a dyn Fn(&amp;T, &amp;T) -&gt; T) -&gt; Self {
        let left_index = 0;
        let right_index = vec.len() - 1;
        Self::new_from_slice(&amp;vec, left_index, right_index, operation)
    }

    fn new_from_slice(
        slice: &amp;[T],
        left_index: usize,
        right_index: usize,
        operation: &amp;'a dyn Fn(&amp;T, &amp;T) -&gt; T,
    ) -&gt; Self {
        if left_index == right_index {
            SegmentTreeNode {
                left_node: None,
                right_node: None,
                left_index,
                right_index,
                info: slice[0],
                operation,
            }
        } else {
            let mid_index = (left_index + right_index) / 2;
            let left_node = Self::new_from_slice(
                &amp;slice[0..=(mid_index - left_index)],
                left_index,
                mid_index,
                operation,
            );
            let right_node = Self::new_from_slice(
                &amp;slice[(mid_index - left_index + 1)..=(right_index - left_index)],
                mid_index + 1,
                right_index,
                operation,
            );

            let info = operation(&amp;left_node.info, &amp;right_node.info);

            SegmentTreeNode {
                left_node: Some(Box::new(left_node)),
                right_node: Some(Box::new(right_node)),
                left_index,
                right_index,
                info,
                operation,
            }
        }
    }

    fn update_index(&amp;mut self, index: usize, info: T) {
        if self.left_index == index &amp;&amp; self.right_index == index {
            self.info = info;
        }

        match (&amp;mut self.left_node, &amp;mut self.right_node) {
            (Some(left_node), Some(right_node)) =&gt; {
                if left_node.right_index &gt;= index {
                    left_node.update_index(index, info);
                } else {
                    right_node.update_index(index, info);
                }
                self.info = (self.operation)(&amp;left_node.info, &amp;right_node.info);
            }
            _ =&gt; (),
        }
    }

    fn range_operation(&amp;self, left_index: usize, right_index: usize) -&gt; T {
        if left_index &lt; self.left_index || right_index &gt; self.right_index {
            panic!(&quot;indexes out of range&quot;)
        }

        if left_index == self.left_index &amp;&amp; right_index == self.right_index {
            return self.info;
        }

        match (&amp;self.left_node, &amp;self.right_node) {
            (Some(left_node), Some(right_node)) =&gt; {
                if right_index &lt;= left_node.right_index {
                    left_node.range_operation(left_index, right_index)
                } else if left_index &gt;= right_node.left_index {
                    right_node.range_operation(left_index, right_index)
                } else {
                    (self.operation)(
                        &amp;left_node.range_operation(left_index, left_node.right_index),
                        &amp;right_node.range_operation(right_node.left_index, right_index),
                    )
                }
            }
            (Some(left_node), None) =&gt; left_node.range_operation(left_index, right_index),
            (None, Some(right_node)) =&gt; right_node.range_operation(left_index, right_index),
            (None, None) =&gt; unreachable!(),
        }
    }
}

struct NumArray&lt;'a&gt; {
    node: SegmentTreeNode&lt;'a, i32&gt;,
}

impl NumArray&lt;'_&gt; {
    fn new(nums: Vec&lt;i32&gt;) -&gt; Self {
        NumArray {
            node: SegmentTreeNode::new_from_vec(nums, &amp;|a: &amp;i32, b: &amp;i32| a + b),
        }
    }

    fn update(&amp;mut self, index: i32, val: i32) {
        self.node.update_index(index as usize, val)
    }

    fn sum_range(&amp;self, left: i32, right: i32) -&gt; i32 {
        self.node.range_operation(left as usize, right as usize)
    }
}

</code></pre></pre>
<h2 id="segment-tree-min-index"><a class="header" href="#segment-tree-min-index">Segment Tree Min Index</a></h2>
<pre><pre class="playground"><code class="language-rust">use std::{
    fmt::Debug,
    cmp::{Ordering, Reverse},
    collections::{BinaryHeap, HashMap, HashSet},
    fmt::Binary,
    hash::Hash,
};

fn main() {
    let  target = vec![1,2,3,2,1];
    let res = Solution::min_number_operations(target);
    println!(&quot;{:?}&quot;, res);
}

struct Solution;

impl Solution {
    pub fn min_number_operations(target: Vec&lt;i32&gt;) -&gt; i32 {
        let root = SegmentTreeNode::new_from_vec(&amp;target);
        Self::dfs(0, target.len() - 1, 0, &amp;root, &amp;target)
    }

    fn dfs(left_idx: usize, right_idx:usize, base: i32, root: &amp;SegmentTreeNode, target: &amp;Vec&lt;i32&gt;) -&gt; i32 {
        if right_idx &lt; left_idx {
            return 0;
        }
        if left_idx == right_idx {
            return target[left_idx] - base;
        }

        let (min_idx, min_val) = root.query_range_min(left_idx, right_idx);
        let mut res = min_val - base;
        if min_idx &gt; 0 { res += Self::dfs(left_idx, min_idx - 1, min_val, root, target); }
        res += Self::dfs(min_idx + 1, right_idx, min_val, root, target);

        res
    }
}


#[derive(Debug)]
struct SegmentTreeNode {
    left_node: Option&lt;Box&lt;SegmentTreeNode&gt;&gt;,
    right_node: Option&lt;Box&lt;SegmentTreeNode&gt;&gt;,
    left_index: usize,
    right_index: usize,
    min_idx: usize,
    min_val: i32,
}

impl SegmentTreeNode{
    fn new_from_vec(vec: &amp;Vec&lt;i32&gt;) -&gt; Self {
        let left_index = 0;
        let right_index = vec.len() - 1;
        Self::new_from_slice(&amp;vec, left_index, right_index)
    }

    fn new_from_slice(
        slice: &amp;[i32],
        left_index: usize,
        right_index: usize,
    ) -&gt; Self {
        if left_index == right_index {
            SegmentTreeNode {
                left_node: None,
                right_node: None,
                left_index,
                right_index,
                min_idx: left_index,
                min_val: slice[0],
            }
        } else {
            let mid_index = (left_index + right_index) / 2;
            let left_node = Self::new_from_slice(
                &amp;slice[0..=(mid_index - left_index)],
                left_index,
                mid_index,
            );
            let right_node = Self::new_from_slice(
                &amp;slice[(mid_index - left_index + 1)..=(right_index - left_index)],
                mid_index + 1,
                right_index,
            );

            let (min_idx, min_val) = if left_node.min_val &lt; right_node.min_val {
                (left_node.min_idx, left_node.min_val)
            } else {
                (right_node.min_idx, right_node.min_val)
            };

            SegmentTreeNode {
                left_node: Some(Box::new(left_node)),
                right_node: Some(Box::new(right_node)),
                left_index,
                right_index,
                min_idx,
                min_val,
            }
        }
    }

    fn query_range_min(&amp;self, left_index: usize, right_index: usize) -&gt; (usize, i32) {
        if right_index &lt; self.left_index || left_index &gt; self.right_index {
            (usize::MAX, i32::MAX)
        } else if left_index &lt;= self.left_index &amp;&amp; right_index &gt;= self.right_index {
            (self.min_idx, self.min_val)
        } else {
            let (left_min_idx, left_min_val) = self.left_node.as_ref().unwrap().query_range_min(left_index, right_index);
            let (right_min_idx, right_min_val) = self.right_node.as_ref().unwrap().query_range_min(left_index, right_index);
            if left_min_val &lt; right_min_val {
                (left_min_idx, left_min_val)
            } else {
                (right_min_idx, right_min_val)
            }
        }
    }
}

</code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="trie"><a class="header" href="#trie">Trie</a></h1>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Debug)]
struct Trie {
    value: char,
    children: HashMap&lt;char, Trie&gt;,
}

impl Trie {
    fn new(value: char) -&gt; Trie {
        Trie {
            value,
            children: HashMap::new(),
        }
    }

    fn from_vec_string(words: Vec&lt;String&gt;) -&gt; Trie {
        let mut root = Trie::new(' ');
        words.into_iter().for_each(|word| root.add_string(word));
        root
    }

    fn from_vec_vec_char(words: &amp;Vec&lt;Vec&lt;char&gt;&gt;) -&gt; Trie {
        let mut root = Trie::new(' ');
        words.iter().for_each(|word| root.add_vec_char(word));
        root
    }

    fn add_string(&amp;mut self, word: String) {
        let word = word.chars().collect();
        self.add_vec_char(&amp;word)
    }

    fn add_vec_char(&amp;mut self, word: &amp;Vec&lt;char&gt;) {
        let mut node = self;
        for character in word.iter() {
            node = node
                .children
                .entry(*character)
                .or_insert(Trie::new(*character))
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rust"><a class="header" href="#rust">Rust</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rust-btreemap-and-btreeset"><a class="header" href="#rust-btreemap-and-btreeset">Rust BTreeMap and BTreeSet</a></h1>
<p>In rust</p>
<ul>
<li>the <code>std::collections::BTreeMap</code> is the implementation of a sorted map.</li>
<li>the <code>std::collections::BTreeSet</code> is the implementation of a sorted set.</li>
</ul>
<h2 id="floor-and-ceil"><a class="header" href="#floor-and-ceil">Floor and Ceil</a></h2>
<h3 id="floor-the-entry-with-the-greatest-key-that-is-less-or-equal-to-a-given-key"><a class="header" href="#floor-the-entry-with-the-greatest-key-that-is-less-or-equal-to-a-given-key">Floor: The Entry with the Greatest Key that is Less or Equal to a Given Key</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>map.range(..=key).next_back().unwrap();
<span class="boring">}
</span></code></pre></pre>
<h3 id="ceil-the-entry-with-the-least-key-that-is-greater-or-equal-to-a-given-key"><a class="header" href="#ceil-the-entry-with-the-least-key-that-is-greater-or-equal-to-a-given-key">Ceil: The Entry with the Least key that is Greater or Equal to a Given Key</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>map.range(key..).next().unwrap();
<span class="boring">}
</span></code></pre></pre>
<h3 id="first"><a class="header" href="#first">First</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let set = BTreeSet::from([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]);
// unstable approach: need `#![feature(map_first_last)]` feature flag
println!(&quot;{:?}&quot;, set.first());
// current approach:
println!(&quot;{:?}&quot;, set.range(..).next());
<span class="boring">}
</span></code></pre></pre>
<h3 id="last"><a class="header" href="#last">Last</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let set = BTreeSet::from([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]);
// unstable approach: need `#![feature(map_first_last)]` feature flag
println!(&quot;{:?}&quot;, set.last());
// current approach:
println!(&quot;{:?}&quot;, set.range(..).next_back());
<span class="boring">}
</span></code></pre></pre>
<h3 id="remove-all-elements-in-a-given-range"><a class="header" href="#remove-all-elements-in-a-given-range">Remove all elements in a given range</a></h3>
<p><em>NOTE: This might not be the most idiomatic rust approach</em></p>
<p>Instead of removing elements from the range one by one, we have to filter out of the element in the range and then re-create the tree-map.</p>
<pre><pre class="playground"><code class="language-rust">use std::collections::BTreeMap;

fn main() {
    let mut map: BTreeMap&lt;usize, usize&gt; = BTreeMap::new();
    map.insert(10, 10);
    map.insert(20, 20);
    map.insert(30, 30);
    map.insert(40, 40);
    map.insert(50, 50);

    map = map
        .into_iter()
        .filter(|(key, _)| *key &lt; 20 || *key &gt;= 40)
        .collect();

    println!(&quot;{:?}&quot;, map);
}

</code></pre></pre>
<h3 id="how-does-it-work"><a class="header" href="#how-does-it-work">How does it work?</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn range&lt;T, R&gt;(&amp;self, range: R) -&gt; Range&lt;'_, K, V&gt;
<span class="boring">}
</span></code></pre></pre>
<p>BTreeMap has an range method that takes a range as input and will output all the entries from the map with a key that is within the given range.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::collections::BTreeSet;
</span><span class="boring">
</span><span class="boring">fn main() {
</span>let set = BTreeSet::from([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]);

// [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
let res = set.range(..);
println!(&quot;{:?}&quot;, res);

// [5, 6, 7, 8, 9]
let res = set.range(5..);
println!(&quot;{:?}&quot;, res);

// [0, 1, 2, 3, 4]
let res = set.range(..5);
println!(&quot;{:?}&quot;, res);

// [0, 1, 2, 3, 4, 5]
let res = set.range(..=5);
println!(&quot;{:?}&quot;, res);

// [4, 5, 6]
let res = set.range(4..=6);
println!(&quot;{:?}&quot;, res);
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="linkedlist"><a class="header" href="#linkedlist">LinkedList</a></h1>
<p>Let's first take a look at how LeetCode define the LinkedList in rust</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(PartialEq, Eq, Clone, Debug)]
pub struct ListNode {
    pub val: i32,
    pub next: Option&lt;Box&lt;ListNode&gt;&gt;,
}
<span class="boring">}
</span></code></pre></pre>
<p>As LeetCode is using <code>Box</code> as the pointer to point to the next node. It does not allow multiple reference to the same node. Hence, to make our life easier, we would like to change the <code>ListNode</code> definition to:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(PartialEq, Eq, Clone, Debug)]
pub struct MutListNode {
    pub val: i32,
    pub next: Option&lt;Rc&lt;RefCell&lt;MutListNode&gt;&gt;&gt;,
}
<span class="boring">}
</span></code></pre></pre>
<ul>
<li>With <code>Rc&lt;T&gt;</code>, we allow multiple ownership to the same <code>MutListNode</code></li>
<li>With <code>RefCell&lt;T&gt;</code>, we allow interior mutability for the heap allocated <code>MutListNode</code></li>
</ul>
<p>To convert between the LeetCode official <code>ListNode</code> and the mutable multi-referencing <code>MutListNode</code> we would need the following conversion utility functions</p>
<p>From <code>Option&lt;Box&lt;ListNode&gt;&gt;</code> to <code>Option&lt;Rc&lt;RefCell&lt;MutListNode&gt;&gt;&gt;</code></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn to_mut_list_node(node: Option&lt;Box&lt;ListNode&gt;&gt;) -&gt; Option&lt;Rc&lt;RefCell&lt;MutListNode&gt;&gt;&gt; {
    match node {
        None =&gt; None,
        Some(node) =&gt; Some(Rc::new(RefCell::new(MutListNode {
            val: node.val,
            next: to_mut_list_node(node.next),
        }))),
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>From <code>Option&lt;Rc&lt;RefCell&lt;MutListNode&gt;&gt;&gt;</code> to <code>Option&lt;Box&lt;ListNode&gt;&gt;</code></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn to_list_node(node: Option&lt;Rc&lt;RefCell&lt;MutListNode&gt;&gt;&gt;) -&gt; Option&lt;Box&lt;ListNode&gt;&gt; {
    match node {
        None =&gt; None,
        Some(node) =&gt; Some(Box::new(ListNode {
            val: node.borrow().val,
            next: to_list_node(node.borrow().next.clone()),
        })),
    }
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="source-code"><a class="header" href="#source-code">Source Code</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(PartialEq, Eq, Clone, Debug)]
pub struct ListNode {
    pub val: i32,
    pub next: Option&lt;Box&lt;ListNode&gt;&gt;,
}

impl ListNode {
    #[inline]
    fn new(val: i32) -&gt; Self {
        ListNode { next: None, val }
    }
}

#[derive(PartialEq, Eq, Clone, Debug)]
pub struct MutListNode {
    pub val: i32,
    pub next: Option&lt;Rc&lt;RefCell&lt;MutListNode&gt;&gt;&gt;,
}

impl MutListNode {
    #[inline]
    fn new(val: i32) -&gt; Self {
        MutListNode { next: None, val }
    }
}

fn to_mut_list_node(node: Option&lt;Box&lt;ListNode&gt;&gt;) -&gt; Option&lt;Rc&lt;RefCell&lt;MutListNode&gt;&gt;&gt; {
    match node {
        None =&gt; None,
        Some(node) =&gt; Some(Rc::new(RefCell::new(MutListNode {
            val: node.val,
            next: to_mut_list_node(node.next),
        }))),
    }
}

fn to_list_node(node: Option&lt;Rc&lt;RefCell&lt;MutListNode&gt;&gt;&gt;) -&gt; Option&lt;Box&lt;ListNode&gt;&gt; {
    match node {
        None =&gt; None,
        Some(node) =&gt; Some(Box::new(ListNode {
            val: node.borrow().val,
            next: to_list_node(node.borrow().next.clone()),
        })),
    }
}

fn vec_to_linked_list(vec: Vec&lt;i32&gt;) -&gt; Option&lt;Box&lt;ListNode&gt;&gt; {
    let mut root = ListNode::new(0);
    let mut curr = &amp;mut root;
    for n in vec {
        curr.next = Some(Box::new(ListNode::new(n)));
        curr = curr.next.as_mut().unwrap();
    }

    root.next
}

fn linked_list_to_vec(node: Option&lt;Box&lt;ListNode&gt;&gt;) -&gt; Vec&lt;i32&gt; {
    let mut vec = vec![];

    let mut curr = node;
    while curr != None {
        vec.push(curr.as_ref().unwrap().val);
        curr = curr.unwrap().next;
    }

    vec
}

fn vec_to_mut_linked_list(vec: Vec&lt;i32&gt;) -&gt; Option&lt;Rc&lt;RefCell&lt;MutListNode&gt;&gt;&gt; {
    let root = Rc::new(RefCell::new(MutListNode::new(0)));
    let mut curr = root.clone();
    for n in vec {
        curr.borrow_mut().next = Some(Rc::new(RefCell::new(MutListNode::new(n))));
        let next = curr.borrow().next.clone().unwrap();
        curr = next;
    }

    let node = root.borrow().next.clone();
    node
}

fn mut_linked_list_to_vec(node: Option&lt;Rc&lt;RefCell&lt;MutListNode&gt;&gt;&gt;) -&gt; Vec&lt;i32&gt; {
    let mut res = vec![];

    let mut curr = node;
    while let Some(curr_node) = curr {
        res.push(curr_node.borrow().val);
        curr = curr_node.borrow().next.clone();
    }

    res
}
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="system-design"><a class="header" href="#system-design">System Design</a></h1>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>After working in the software industry for over two years, I have learned a lot about what is hiring manager and interviewer looking for when hiring a new software development engineer. Nevertheless, to become an senior/staff engineer, there is still a long way to go. Since I departed from my first job at AWS, I have been trying to learn from lectures, books, and keynote presentations regarding the knowledge and skills that I need to tackle a system design interview. Here, is where I keep all my notes. It is not a guide, it is not a book, it is not even well-organized at all. However, it is where I keep the knowledge that I have learned so far.</p>
<h2 id="system-design-interview"><a class="header" href="#system-design-interview">System Design Interview</a></h2>
<h3 id="what-is-a-system-design-interview"><a class="header" href="#what-is-a-system-design-interview">What is a system design interview?</a></h3>
<ul>
<li>simulate in-team design process</li>
<li>solve an ambiguous problem</li>
<li>work with teammates/co-workers</li>
<li>two co-workers working together</li>
</ul>
<h3 id="what-are-the-desireable-traits"><a class="header" href="#what-are-the-desireable-traits">What are the desireable traits</a></h3>
<ul>
<li>ability to collaborate with teammates</li>
<li>work under pressure</li>
<li>work with ambiguous problem</li>
<li>constructive problem solving skills</li>
</ul>
<h4 id="how-does-the-interviewer-evaluate-the-desirable-traits"><a class="header" href="#how-does-the-interviewer-evaluate-the-desirable-traits">How does the interviewer evaluate the desirable traits</a></h4>
<ul>
<li>work with ambiguous problem
<ul>
<li>does the candidate asks requirement clarification?</li>
</ul>
</li>
</ul>
<h3 id="what-are-the-undesirable-traits"><a class="header" href="#what-are-the-undesirable-traits">What are the undesirable traits</a></h3>
<ul>
<li>over-engineering solution</li>
<li>stubbornness</li>
<li>do not answer without thinking, or without understanding the question's scope, requirements, backgrounds, etc.</li>
</ul>
<h3 id="does-and-donts"><a class="header" href="#does-and-donts">Does and Don'ts</a></h3>
<p><strong>Dos</strong></p>
<ul>
<li>ask for clarification, do not make assumptions without verify with the interviewer</li>
<li>thinking aloud - communicate</li>
<li>make multiple design proposals</li>
<li>design the most critical parts first</li>
<li>ask for hints when stuck</li>
</ul>
<p><strong>Don'ts</strong></p>
<ul>
<li>do not go into detailed design in the early stage</li>
<li>do not thinking alone</li>
</ul>
<h3 id="the-approach"><a class="header" href="#the-approach">The approach</a></h3>
<p><strong>Approaches - four stages</strong></p>
<ol>
<li>Comprehend the requirement</li>
<li>Propose high-level designs</li>
<li>Detailed designs</li>
<li>Discussions</li>
</ol>
<h4 id="stage-1-comprehend-the-requirement"><a class="header" href="#stage-1-comprehend-the-requirement">Stage 1: Comprehend the requirement</a></h4>
<p><em>After the interviewer asked the question, the candidate should list out the following 5 catagories of questions on the whiteboard/notepad. Then, the candidate can asks the following questions listed for each catagories. For each question asked, take notes on the information provided by the interviewer (e.g. user is an machine learning algorithm). If the information hits a design preference, please also take notes on the possible design solution (i.e. use gRPC streaming / use map-reduce).</em></p>
<ul>
<li><strong>User/Customer:</strong> what does the customer/end-user wants?
<ul>
<li>who is the user? and, how will the user use the product?</li>
<li>how the system will be used?
<ul>
<li>is the data going to be retrieved frequently? in real time? or by a cron job?</li>
</ul>
</li>
<li>what product feature is the customer looking for?</li>
<li>what problem is the customer trying to solve?</li>
</ul>
</li>
<li><strong>Scale:</strong> what is the scale of the system?
<ul>
<li>to understand how would our system handle the growing number of customers?</li>
<li>how many users?</li>
<li>what is the avg/p100 qps?</li>
<li>what is the size of the data per request?</li>
<li>do we need to handler spikes in traffic? what is the difference between peak traffic and average traffic</li>
<li>when does the customer need to scale 10x/100x</li>
</ul>
</li>
<li><strong>Performance:</strong> what is the performance requirement of the system?
<ul>
<li>what is expected write-to-read delay?
<ul>
<li>can we use batch processing?</li>
<li>can we use stream processing?</li>
<li>do we need to use SSE/websocket for server-side push?</li>
</ul>
</li>
<li>what is the expected P99 latency for read queries?</li>
</ul>
</li>
<li><strong>Cost:</strong> what is the cost limit (budget constrain) of the system?
<ul>
<li>should the design minimized the cost of development?</li>
<li>should the design minimized the cost of dev/ops (maintenance)?</li>
</ul>
</li>
<li><strong>Tech Stack:</strong> understand the technology the team is using
<ul>
<li>AWS? GCP? Azure?</li>
<li>Java? Rust? Python?</li>
<li>GraphQL? gRPC? REST?</li>
</ul>
</li>
</ul>
<h4 id="stage-2-list-out-the-functionalnon-function-requirements"><a class="header" href="#stage-2-list-out-the-functionalnon-function-requirements">Stage 2: List out the Functional/Non-Function Requirements</a></h4>
<p><em>After comprehend the question via asking clarification questions, the candidate can start list out the function requirements and the non-functional requirements. Make sure the interviewer is on the same page with the candidate. Also, please write down the functional requirement (i.e. API design) and non-functional requirements on the white board.</em></p>
<ul>
<li>
<p><strong>Functional Requirements</strong></p>
<ul>
<li>What does the APIs looks like? Input parameters? Output parameters?</li>
<li>What are the set of the operation that the system would support?</li>
</ul>
</li>
<li>
<p><strong>Non-Functional Requirements</strong></p>
<ul>
<li>Scalability</li>
<li>Performance</li>
<li>Availability</li>
<li>Consistency</li>
<li>Cost</li>
</ul>
</li>
</ul>
<h4 id="stage-3-propose-high-level-designs"><a class="header" href="#stage-3-propose-high-level-designs">Stage 3: Propose high-level designs</a></h4>
<p><em>Once we have listed out all of the functional and non-functional requirements, we can start with something sample, such as a monolith with a front-end, a backend server, and a database.</em></p>
<ul>
<li>propose design for different scales
<ul>
<li>get the interviewers involved</li>
</ul>
</li>
<li>make some estimation on the traffic/scale
<ul>
<li>dive deep only if the interviewer is asking for deeper analysis</li>
</ul>
</li>
<li>draw some components on the whiteboard for the high-level design
<ul>
<li>a frontend (e.g. Website/iOS/Android)</li>
<li>an api gateway</li>
<li>a load balancer</li>
<li>a backend service (running on EC2/ECS/AppRunner/Lambda)</li>
<li>a queue (if needed) (e.g. AWS SQS/Kafka/RocketMQ)</li>
<li>a database (if needed) (SQL/NoSQL) (e.g. AWS DynamoDB/Mongo/MySQL)</li>
<li>a data warehouse (if needed) ()</li>
<li>a batch processing service (if needed) (e.g. map-reduce)</li>
</ul>
</li>
</ul>
<h4 id="stage-4-detailed-design"><a class="header" href="#stage-4-detailed-design">Stage 4: Detailed design</a></h4>
<p><em>For each components listed during the previous stage, discuss with the interviewer which part we should dive deeper to propose an detailed design. If the interviewer did not provide any preference, the candidate can pick the part that the candidate has the most in-depth knowledge to discuss/design further.</em></p>
<ul>
<li>design/discuss the api schema
<ul>
<li>REST/gRPC/GraphQL</li>
</ul>
</li>
<li>design/discuss the data schema
<ul>
<li>should we store individual data or aggregate data</li>
</ul>
</li>
<li>pick/discuss the database paradigms
<ul>
<li>should we use relational or key-value stores</li>
</ul>
</li>
<li>pick/discuss the usage of stream/batch process for the system
<ul>
<li>should we use a queue to buffer the request?</li>
<li>should we store the data somewhere and process them together latter?</li>
</ul>
</li>
<li>design/discuss the backend processing service
<ul>
<li>where to run the service? EC2/ECS/AppRunner/Lambda? trade-off? development cost vs operational cost?</li>
<li>how does the logic in the back end processing services looks like?
<ul>
<li>objected oriented design</li>
<li>using local cache?</li>
</ul>
</li>
<li>how would it update the database?
<ul>
<li>per-request or batched</li>
<li>sync or async (queue)</li>
<li>user push or server pull?</li>
</ul>
</li>
<li>single thread or multi thread?</li>
<li>internal dead-letter queue?</li>
</ul>
</li>
</ul>
<h4 id="stage-5-discussions"><a class="header" href="#stage-5-discussions">Stage 5: Discussions</a></h4>
<p><em>After finish the detailed design, the candidate and the interviewer can have a discussion regarding the pro/cons of the system such as the limitation and bottlenecks. How would the DevOps looks like during operation? How would the system handle disaster recovery? It is a great opportunity to demonstrate to the interviewer the depth and width of the knowledge of the candidate.</em></p>
<ul>
<li>limitation</li>
<li>bottlenecks</li>
<li>disaster recovery</li>
<li>dev-ops</li>
</ul>
<h3 id="question-to-ask"><a class="header" href="#question-to-ask">Question to ask:</a></h3>
<h4 id="data-schema"><a class="header" href="#data-schema">Data schema</a></h4>
<div class="table-wrapper"><table><thead><tr><th></th><th>Individual Data</th><th>Aggregated Data</th></tr></thead><tbody>
<tr><td>Pro</td><td><ul><li>Fast to write</li><li>The data is flexible for future processing</li></ul></td><td><ul><li>Fast to read</li><li>The data is ready to be used</li></ul></td></tr>
<tr><td>Con</td><td><ul><li>Slow to read</li><li>Costly to store</li></ul></td><td><ul><li>Usage is limited by the aggregation method</li><li>Requires data aggregation</li><li>Hard to fix pervious aggregation errors</li></ul></td></tr>
</tbody></table>
</div>
<p>Ask: what is the expected data day?</p>
<ul>
<li>Few milliseconds/seconds -&gt; store the individual data (stream processing)</li>
<li>Few minutes -&gt; store the individual data / aggregate the data on the fly</li>
<li>Few hours -&gt; aggregate the data using an aggregation pipeline / batch jobs (map-reduce)</li>
</ul>
<h4 id="data-store-types"><a class="header" href="#data-store-types">Data Store Types</a></h4>
<ul>
<li>Answer: How to scale write?</li>
<li>Answer: How to scale reads?</li>
<li>Answer: How to scale both write and reads?</li>
<li>Answer: How to handle network partitions and hardware faults?</li>
<li>Answer: Consistency model?</li>
<li>Answer: How to recover data?</li>
<li>Answer: Data security?</li>
<li>Answer: How to make the data schema extensible for future changes?</li>
</ul>
<h4 id="eventrequest-processing-backend-service"><a class="header" href="#eventrequest-processing-backend-service">Event/Request Processing Backend Service</a></h4>
<ul>
<li>
<p>Answer: How to scale?</p>
</li>
<li>
<p>Answer: How to achieve high throughput?</p>
</li>
<li>
<p>Answer: How to handle instances failure?</p>
</li>
<li>
<p>Answer: How to handle database failure? Unable to connect to database?</p>
</li>
<li>
<p>Checkpoint:</p>
<ul>
<li>the client write the request into a queue</li>
<li>the processing server pull from the queue, process it, write to database, the update the checkpoint offset</li>
</ul>
</li>
<li>
<p>Partitioning:</p>
<ul>
<li>have several queue (use hashing to pick a queue)</li>
</ul>
</li>
</ul>
<h4 id="others"><a class="header" href="#others">OTHERS</a></h4>
<ul>
<li>Blocking or Non-Blocking I/O</li>
<li>Stream Service or Batch Service</li>
<li>Buffering or Batching the request</li>
<li>Timeouts / Retries (Thundering heard) (Exponential Back-Off / Jitter)</li>
<li>Circuit Breaker</li>
<li>Load Balancing: Using a Load Balancer or Service Mesh</li>
<li>Service discovery (Server-Side/Client-Side)? DNS? Auto Scaling Group? Health Check? ZooKeeper?</li>
<li>Sharding (For invoke / For database) (Sharding/Partition Strategy) (Hot Partition) (Consistent Hashing)</li>
<li>Replications of server node (leader/leaderless)</li>
<li>Data format (JSON/BSON/Thrift/ProtoBuf)</li>
<li>Testing
<ul>
<li>correctness: unit test / functional test / integration test</li>
<li>performance: load test / stress test / soak test</li>
<li>monitoring: canary test</li>
</ul>
</li>
<li>monitoring:
<ul>
<li>logging: cloudwatch / elastic search / kibana</li>
<li>metrics: cloudwatch / grafana</li>
<li>alarm: cloudwatch</li>
</ul>
</li>
</ul>
<h2 id="references"><a class="header" href="#references">References</a></h2>
<ul>
<li>Alex Xu - <em>System Design Interview - An Insider's Guide</em></li>
<li>Mikhail Smarshchok - <em>System Design Interview - Step By Step Guile</em></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="system-design-fundamentals"><a class="header" href="#system-design-fundamentals">System Design Fundamentals</a></h1>
<p>Vertical/Horizontal Scaling</p>
<ul>
<li>Vertical Scaling</li>
<li>Horizontal Scaling</li>
</ul>
<p>Share Nothing Architecture</p>
<ul>
<li>Different machine on the same machine do not share physical resources (CPU, MEM, etc.)</li>
<li></li>
</ul>
<p>What makes distributed computing different from local computing</p>
<ul>
<li>Latency: Processor speed vs network speed</li>
<li>Memory Access: No pointers -&gt; Share data via sending messages</li>
<li>Partial Failures: Unavoidable on distributed system</li>
</ul>
<p>8 Fallacies of Distributed Systems</p>
<ol>
<li>The network is reliable</li>
<li>Latency is ZERO</li>
<li>Bandwidth is infinite</li>
<li>The network is secure</li>
<li>Topology does not changes</li>
<li>There is only one administrator</li>
<li>Transport cost $0</li>
<li>The network is homogeneous</li>
</ol>
<p>The Byzantine General Problem</p>
<p>Latency -&gt; How to set a</p>
<p>Fischer Lynch Paterson Correctness result</p>
<ul>
<li>Distributed consensus is impossible when at least one process might fail</li>
</ul>
<p>To manage uncertainty we have mitigation strategies</p>
<ul>
<li>APPROACH 1: Limit who can write at a given time
<ul>
<li>Leader-Follower pattern</li>
</ul>
</li>
<li>APPROACH 2: Make rules for how many yes in the system
<ul>
<li>raft - consensus algorithm</li>
</ul>
</li>
</ul>
<p>Mental modal calibration</p>
<ul>
<li>Incident analysis - post mortem
<ul>
<li>fresh learning</li>
</ul>
</li>
</ul>
<p>Request Validation</p>
<ul>
<li>Check the request is hitting an valid API</li>
<li>Check the request consist all required parameters</li>
<li>Check the request parameters are within the valid range</li>
</ul>
<p>Authentication / Authorization</p>
<ul>
<li>Authentication: validate the identity of the user/service</li>
<li>Authorization: check the user/service has the permission for the given action</li>
</ul>
<p>TLS / SSL Termination</p>
<ul>
<li>Decrypting the TLS/SSL request and pass the un-encrypted request to the backend services</li>
</ul>
<p>Request Dispatching</p>
<ul>
<li>Sending the request to the appropriate backend service</li>
</ul>
<p>Request De-duplication
*</p>
<p>Metrics Collection
*</p>
<p>Bulkhead Pattern</p>
<p>Circuit Breaker Pattern</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="algorithms-1"><a class="header" href="#algorithms-1">Algorithms</a></h1>
<p><em>When dealing with system design questions such as designing a rate limiting system, a sharding system, or a global location service, candidate can use some of the following system design algorithms during the interview.</em></p>
<h2 id="leaky-bucket-algorithms"><a class="header" href="#leaky-bucket-algorithms">Leaky Bucket Algorithms</a></h2>
<p><strong>Use-case</strong>: Rate Limiting Systems</p>
<p><strong>Process</strong></p>
<ol>
<li>a client send a message to the server</li>
<li>the server uses an sharding algorithms to find the corresponding bucket for the message</li>
<li>the server tries to append the message to the bucket - a local message queue
<ul>
<li>if the queue is full (i.e. has <code>bucket_size</code> message in the queue already), then drop the message</li>
<li>if the queue has space, append the message to the end of the queue</li>
</ul>
</li>
<li>the consumer will pull message from the queue with a rate of <code>drain_rate</code></li>
<li>the consumer process the message</li>
</ol>
<p><strong>Parameters</strong></p>
<ul>
<li><code>bucket_size</code>: the maximum amount of messages can be stored in each bucket</li>
<li><code>drain_rate</code>: the speed that the message is been consumed from the bucket</li>
</ul>
<p><img src=".system_design/../system_design/fundamentals/./images/algorithms_000.png" alt="Leaky Bucket Algorithms" /></p>
<h2 id="token-bucket-algorithms"><a class="header" href="#token-bucket-algorithms">Token Bucket Algorithms</a></h2>
<p><strong>Use-case</strong>: Rate Limiting System</p>
<p><strong>Process</strong></p>
<ol>
<li>a client send a message to the server</li>
<li>the server uses an sharding algorithms to find the corresponding bucket for the message</li>
<li>the server tries to acquire a token from the bucket
<ul>
<li>if a token is acquired, the request is processed</li>
<li>if no token exist in the bucket, the request is dropped</li>
</ul>
</li>
<li>the bucket receive a refill of <code>refill_size</code> amount of token each for each <code>refill_rate</code> interval</li>
<li>the amount of token can be stored in the bucket is limited by the <code>bucket_size</code></li>
</ol>
<p><strong>Parameters</strong></p>
<ul>
<li><code>bucket_size</code>: the maximum amount of token can be stored in each bucket</li>
<li><code>refill_size</code>: the amount of token</li>
<li><code>refill_rate</code>: the time interval between each refill</li>
</ul>
<p><strong>Alteration</strong></p>
<ul>
<li><em>token per request</em>: for each token, the system can process one message. if there are <code>n</code> message, then it would requires <code>n</code> token from the bucket for all the message to be processed.</li>
<li><em>token per bytes</em>: for each token, the system can process <code>x</code> byte of message. if there are <code>n</code> message each with <code>s</code> size, then it would requires <code>CEIL(x / s) * n</code> tokens from the bucket for all message to be processed.</li>
</ul>
<p><img src=".system_design/../system_design/fundamentals/./images/algorithms_001.png" alt="Token Bucket Algorithms" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="consistency"><a class="header" href="#consistency">Consistency</a></h1>
<h2 id="definitions"><a class="header" href="#definitions">Definitions</a></h2>
<p><strong>Consensus</strong>: The methods to get all of the instances/nodes in the system to agree on something.</p>
<p><strong>Eventual Consistency (Convergence)</strong>: All replicas in the system will eventually converge to the same value after an unspecified length of time.</p>
<p><strong>Faults Tolerant</strong>: The ability of keeping the software system functioning correctly, even if some internal component is faulty.</p>
<p><strong>Linearizability</strong>: The system appears as if there is only one copy of data, and all operation on the data are atomic.</p>
<p><strong>Split Brain</strong>: More than one instance/node in the system believe that they are the leader in a single-leader system.</p>
<p><strong>Strict Serializability / Strong One-Copy Serializability</strong>: The database/system satisfy both the serializability and linearizability requirements.</p>
<h2 id="replication-methods"><a class="header" href="#replication-methods">Replication Methods</a></h2>
<ul>
<li>Single-Leader Replication</li>
<li>Multi-Leader Replication</li>
<li>Leaderless Replication</li>
</ul>
<h2 id="linearizability"><a class="header" href="#linearizability">Linearizability</a></h2>
<p><strong>Requirement of Linearizability</strong></p>
<ul>
<li>After one read has returned an updated value, all following read by the same client and all other clients must also returns the same updated value.</li>
</ul>
<h3 id="linearizability-of-replication-models"><a class="header" href="#linearizability-of-replication-models">Linearizability of Replication Models</a></h3>
<h4 id="single-leader-replication---potentially-linearizable"><a class="header" href="#single-leader-replication---potentially-linearizable">Single-leader Replication - Potentially Linearizable</a></h4>
<p>Example: MongoDB with <code>linearizable</code> Read Concern</p>
<p>A single-leader replication system can become fully <em>linearizable</em> if the following condition are met</p>
<ol>
<li>All write and read are done via the leader node</li>
<li>All client and knows who is the leader node.</li>
</ol>
<p>Failover might cause the system violate the <em>linearizability</em> concern</p>
<ol>
<li>When using asynchronous replication, the lost of committed writes would cause the system to violate the <em>linearizability</em> and <em>durability</em> requirements</li>
<li>When using synchronous replication, the system meet the <em>linearizability</em> and <em>durability</em> requirements, but the system will be slow.</li>
</ol>
<h4 id="multi-leader-replication---not-linearizable"><a class="header" href="#multi-leader-replication---not-linearizable">Multi-leader Replication - Not Linearizable</a></h4>
<p>Example:</p>
<p>Since there are multiple copy of the data handled by multiple leaders, and the replication of the data are done asynchronously, the multi-leader replication system cannot meet the <em>linearizability</em> requirements.</p>
<h4 id="leaderless-replication---not-linearizable-most-of-the-cases"><a class="header" href="#leaderless-replication---not-linearizable-most-of-the-cases">Leaderless Replication - Not Linearizable (Most of the Cases)</a></h4>
<p>Example:</p>
<h4 id="consensus-algorithms---linearizable"><a class="header" href="#consensus-algorithms---linearizable">Consensus Algorithms - Linearizable</a></h4>
<p>Example: etcd and ZooKeeper</p>
<p>Consensus algorithms has built-in measures to avoid/prevent split brain and stale replicas, which allows the consensus algorithms to meed the <em>linearizability</em> requirements.</p>
<h2 id="cap-theorem"><a class="header" href="#cap-theorem">CAP Theorem</a></h2>
<ul>
<li>Characteristics
<ul>
<li>Consistency
<ul>
<li>All nodes on the network must return the same data</li>
<li>HARD!!!!!!</li>
<li>Requires: Instant and universal replication</li>
<li>Eventual Consistency does not count: It's not the C in CAP</li>
<li>Consistency is not a binary state, there are many degrees of consistency</li>
</ul>
</li>
<li>Availability</li>
<li>Partition Tolerance
<ul>
<li>Network partition occur when network connectivity between two nodes is interrupted</li>
</ul>
</li>
</ul>
</li>
<li>Theorem
<ul>
<li>NOT TRUE
<ul>
<li>A distributed system can deliver only two of the three characteristics</li>
</ul>
</li>
<li>TRUE
<ul>
<li>Partition Tolerance is required; to avoid partition tolerance, there can only be one service, which is not a distributed system</li>
<li>Hence, all distributed system need to balance between consistency and availability</li>
</ul>
</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="technologies"><a class="header" href="#technologies">Technologies</a></h1>
<h2 id="push-notification-service-providers"><a class="header" href="#push-notification-service-providers">Push Notification Service Providers</a></h2>
<p>For each platform (iOS, Androids, e-mails, etc), our service would need to utilized the following push notification service provider to send message to our end users.</p>
<ul>
<li>iOS:
<ul>
<li>APNs - Apple Push Notification Service</li>
</ul>
</li>
<li>Android:
<ul>
<li>FCM - Firebase Cloud Messaging for Android</li>
</ul>
</li>
<li>e-mail:
<ul>
<li>AWS SES - Amazon Simple Email Service</li>
<li>SendGrid</li>
<li>MailGun</li>
<li>You can always build your own email service</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="four-distributed-systems-architectural-patterns---by-tim-berglund"><a class="header" href="#four-distributed-systems-architectural-patterns---by-tim-berglund">Four Distributed Systems Architectural Patterns - by Tim Berglund</a></h1>
<p>https://www.youtube.com/watch?v=BO761Fj6HH8</p>
<div class="table-wrapper"><table><thead><tr><th>Overall Rating</th><th>Modern Three Tier</th><th>Sharded</th><th>Batch + Stream</th><th>Event Bus</th></tr></thead><tbody>
<tr><td>Scalability</td><td>4/5</td><td>3/5</td><td>5/5</td><td>5/5</td></tr>
<tr><td>Coolness</td><td>2/5</td><td>1/5</td><td>1/5</td><td>5/5</td></tr>
<tr><td>Difficult</td><td>3/5</td><td>4/5</td><td>5/5</td><td>4/5</td></tr>
<tr><td>Flexibility</td><td>5/5</td><td>3/5</td><td>2/5</td><td>5/5</td></tr>
</tbody></table>
</div>
<h2 id="pattern-1---modern-three-tier"><a class="header" href="#pattern-1---modern-three-tier">Pattern 1 - Modern Three-Tier</a></h2>
<pre><code> -----------------    -------------    ---------
|Presentation Tier|--|Business Tier|--|Data Tier|
 -----------------    -------------    ---------
</code></pre>
<pre><code> ----------           ---------    -----------
| React JS |-- ELB --| Node JS |--| Cassandra |
 ----------           ---------    -----------
</code></pre>
<ol>
<li>Presentation Tier - React JS
<ul>
<li>stateless - on client</li>
</ul>
</li>
<li>Business Tier - Node JS
<ul>
<li>stateless - on server</li>
</ul>
</li>
<li>Data Tier - Cassandra</li>
</ol>
<p>Cassandra</p>
<ul>
<li>all nodes on the Cassandra cluster is the same</li>
<li>assign each node a token (hash range) - for sharding</li>
<li>hash the input - write/read the message from the server which contain the hash range</li>
<li>write replicas to the next X nodes</li>
</ul>
<p><strong>strengths</strong> of the modern three tier</p>
<ul>
<li>reach front-end frameworks</li>
<li>scalable middle tier - stateless</li>
<li>infinitely scalable data tire - with cassandra</li>
</ul>
<p><strong>weaknesses</strong> of the modern three tier</p>
<ul>
<li>need to keep the middle tier stateless for scalability</li>
</ul>
<h2 id="pattern---shard"><a class="header" href="#pattern---shard">Pattern - Shard</a></h2>
<p>Break up the system into several shard, where each shard is a complete system</p>
<p>Good real-world examples:</p>
<ul>
<li>Slack</li>
</ul>
<p><strong>Stage 1</strong></p>
<pre><code> --------      ----------------------      ----------
| Client | -- | Complete Application | -- | Database |
 --------      ----------------------      ----------
</code></pre>
<p><strong>Stage 2</strong></p>
<pre><code> --------      --------      ----------------------      ----------
| Client | -- |        | -- | Complete Application | -- | Database |
 --------     |        |     ----------------------      ----------
 --------     |        |     ----------------------      ----------
| Client | -- | Router | -- | Complete Application | -- | Database |
 --------     |        |     ----------------------      ----------
 --------     |        |     ----------------------      ----------
| Client | -- |        | -- | Complete Application | -- | Database |
 --------      --------      ----------------------      ----------
</code></pre>
<p><strong>strengths</strong> of shard</p>
<ul>
<li>client isolation is easy (data and deployment)</li>
<li>known, simple technologies</li>
</ul>
<p><strong>weaknesses</strong> of shard</p>
<ul>
<li>complexity: monitoring, routing</li>
<li>no comprehensive view of data (need to merge all data)</li>
<li>oversized shards -&gt; a shard become a distributed system on itself</li>
<li>difficult to re-shard; need to design the sharding schema upfront</li>
</ul>
<h2 id="pattern-3---batch--stream"><a class="header" href="#pattern-3---batch--stream">Pattern 3 - Batch + Stream</a></h2>
<p>Streaming vs Batch ?</p>
<ul>
<li>streaming - data is coming in in real time</li>
<li>batch - data that is store somewhere</li>
</ul>
<p>Batch + Stream - assumes unbounded, immutable data</p>
<pre><code> --------      ----------------------      ----------
| Source | -- | batch processing     | -- | Scalable |
| of     |     ----------------------     | Database |
| Event  |     ----------------------     |          |
|        | -- | streaming processing | -- |          |
 --------      ----------------------      ----------
</code></pre>
<p>batch processing</p>
<ul>
<li>long-term storage</li>
<li>bounded analysis</li>
<li>high latency</li>
</ul>
<p>streaming processing</p>
<ul>
<li>temporary queueing</li>
<li>unbounded computation</li>
<li>low latency</li>
</ul>
<pre><code> --------      ----------------------      -----------
| Kafka  | -- | Cassandra + Spark    | -- | Cassandra |
|        |     ----------------------     |           |
|        |     ----------------------     |           |
|        | -- | Event frameworks     | -- |           |
 --------      ----------------------      -----------
</code></pre>
<p>Kafka</p>
<ul>
<li>producer</li>
<li>consumer</li>
<li>topic
<ul>
<li>named queue</li>
<li>can be partitioned</li>
</ul>
</li>
</ul>
<p>topic partitioning</p>
<ul>
<li>the queue become unordered</li>
<li>because partition does not track order in other partition</li>
</ul>
<p><strong>strengths</strong> of batch + stream</p>
<ul>
<li>optimized subsystems based on operational requirements</li>
<li>good at unbounded data</li>
</ul>
<p><strong>weaknesses</strong> of batch + stream</p>
<ul>
<li>complex to operate and maintain</li>
</ul>
<h2 id="pattern-4---event-bus"><a class="header" href="#pattern-4---event-bus">Pattern 4 - Event Bus</a></h2>
<ul>
<li>integration is a first-class concern</li>
<li>life is dynamic; database are static</li>
<li>table are streams and streams are tables</li>
<li>keep your services close, your computer closer</li>
</ul>
<p>Storing Data in Message Queue</p>
<ul>
<li>Retention policy (e.g. can be forever)</li>
<li>high I/O performance</li>
<li>O(1) writes, O(1)reads</li>
<li>partitioning, replication</li>
<li>elastic scale</li>
</ul>
<p>first-class event - event or request ?</p>
<ul>
<li>request
<ul>
<li>request</li>
<li>response</li>
</ul>
</li>
<li>event
<ul>
<li>produce</li>
<li>consume</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="api-design-graphql-vs-grpc-vs-rest"><a class="header" href="#api-design-graphql-vs-grpc-vs-rest">API Design: GraphQL vs. gRPC vs. REST</a></h1>
<ul>
<li>They are different tools for different jobs</li>
</ul>
<p>Design Considerations: there is always a best API style for the problem</p>
<h2 id="api-styles"><a class="header" href="#api-styles">API Styles</a></h2>
<ul>
<li>Query APIs
<ul>
<li>Flexibility</li>
<li>For client to retrieve data from the server</li>
</ul>
</li>
<li>Flat File APIs
<ul>
<li>SFTP</li>
</ul>
</li>
<li>Streaming APIs</li>
<li>RPC APIs
<ul>
<li>gRPC, thrift</li>
<li>A component calling another components and hide the in-between networking</li>
</ul>
</li>
<li>Web APIs</li>
</ul>
<h2 id="rpc---remote-procedure-call-grpc-apache-thrift-coral"><a class="header" href="#rpc---remote-procedure-call-grpc-apache-thrift-coral">RPC - Remote Procedure Call (gRPC, Apache Thrift, Coral)</a></h2>
<ul>
<li>Model the function of the server</li>
<li>Data over the wire (HTTP/2 + protobuf)</li>
</ul>
<p>Advantages:</p>
<ul>
<li>Simple and Easy to Understand</li>
<li>Lightweight payloads</li>
<li>High performance</li>
</ul>
<p>Disadvantages:</p>
<ul>
<li>Tight coupling
<ul>
<li>the client and server need to understand each others</li>
</ul>
</li>
<li>No discoverability
<ul>
<li>no way to understand the api without taking a look at the documentation</li>
</ul>
</li>
<li>Function explosion
<ul>
<li>An api/function for an specific job; ends up with a lot of api/functions</li>
</ul>
</li>
</ul>
<p>Good For:</p>
<ul>
<li>Micro-services</li>
</ul>
<h2 id="rest---representational-state-transfer-json-ion"><a class="header" href="#rest---representational-state-transfer-json-ion">REST - Representational State Transfer (json, ION)</a></h2>
<ul>
<li>
<p>Model the resource of the server</p>
</li>
<li>
<p>States machines over the wire</p>
</li>
<li>
<p>For API longevity, not for short-term efficiency</p>
</li>
<li>
<p>Reduce Server-Client coupling</p>
</li>
</ul>
<p>Entry point</p>
<ul>
<li>client sending a request to the entry point</li>
<li>server sending back the metadata of the api</li>
</ul>
<p>e.g.</p>
<pre><code>GET http://example.com

{
    &quot;conversations&quot;: {...},
    &quot;title&quot;: {...},
}

GET http://example.com/conversions

{
    &quot;count&quot;: 3,
    &quot;value&quot;: [...],
}

GET http://example.com/conversions/2/title

{
    &quot;title&quot;: &quot;hello world&quot;,
}
</code></pre>
<p>Without any documentation, the user can understand how to use the api by taking a look at the metadata returned from the server.</p>
<p>Describe the operation on the resource</p>
<p>Advantages:</p>
<ul>
<li>Decoupled Client and Server</li>
<li>API can evolve overtime</li>
<li>Reuses HTTP
<ul>
<li>HTTP verbs (GET POST UPDATE ...)</li>
</ul>
</li>
</ul>
<p>Disadvantages:</p>
<ul>
<li>No single spec
<ul>
<li>Different people are having different understanding of REST</li>
</ul>
</li>
<li>Big payloads and Chattiness
<ul>
<li>Returning a lot of reach metadata</li>
<li>Chattiness: the client need to make a lot of API calls to accomplish an job</li>
</ul>
</li>
</ul>
<h2 id="graphql---graph-query-language"><a class="header" href="#graphql---graph-query-language">GraphQL - Graph Query Language</a></h2>
<p>Model the query</p>
<ul>
<li>Requesting what exactly what the clients want</li>
</ul>
<p>Schema definition</p>
<ul>
<li>Defined the types and query that the client can be made</li>
</ul>
<p>e.g.</p>
<pre><code>{
    listCoversitions {
        title,
        message {
            text
        }
    }
}
</code></pre>
<p>Advantages</p>
<ul>
<li>Low network overhead</li>
<li>Typed schema</li>
<li>Fits graph-like data very well</li>
</ul>
<p>Disadvantages</p>
<ul>
<li>Complexity - harder for the backend than REST &amp; RPC</li>
<li>Caching - always HTTP POST (i.e. no http caching)</li>
<li>Versioning</li>
<li>Still early</li>
</ul>
<div class="table-wrapper"><table><thead><tr><th></th><th>Coupling</th><th>Chattiness</th><th>Client Complexity</th><th>Cognitive Complexity</th><th>Caching</th><th>Discoverability</th></tr></thead><tbody>
<tr><td><strong>RPC - Functions</strong></td><td>High</td><td>Medium</td><td>Low</td><td>Low</td><td>Custom</td><td>Bad</td></tr>
<tr><td><strong>REST - Resources</strong></td><td>Low</td><td>High</td><td>Low</td><td>Low</td><td>HTTP</td><td>GOOD</td></tr>
<tr><td><strong>GraphQL - Queries</strong></td><td>Medium</td><td>Low</td><td>High</td><td>High</td><td>Custom</td><td>Good</td></tr>
</tbody></table>
</div>
<h2 id="use-case-management-api"><a class="header" href="#use-case-management-api">Use Case: Management API</a></h2>
<p>Solution: REST
Consideration:</p>
<ul>
<li>Focus on objects or resources</li>
<li>Many varied client</li>
<li>Discoverability and documentation</li>
</ul>
<h2 id="use-case-command-api"><a class="header" href="#use-case-command-api">Use Case: Command API</a></h2>
<p>Solution: RPC
Consideration:</p>
<ul>
<li>Action-oriented</li>
<li>Simple interaction</li>
</ul>
<h2 id="use-case-internal-microservice"><a class="header" href="#use-case-internal-microservice">Use Case: Internal Microservice</a></h2>
<p>Solution: RPC
Consideration:</p>
<ul>
<li>Tightly coupled services</li>
<li>High performance</li>
</ul>
<h2 id="use-case-data-or-mobile-api"><a class="header" href="#use-case-data-or-mobile-api">Use Case: Data or Mobile API</a></h2>
<p>Solution: GraphQL
Consideration:</p>
<ul>
<li>Data is Graph-like</li>
<li>Optimize for high latency</li>
</ul>
<h2 id="use-case-composite-api---backend-for-frontend"><a class="header" href="#use-case-composite-api---backend-for-frontend">Use Case: Composite API - Backend for Frontend</a></h2>
<p>Solution: GraphQL
Considerations:</p>
<ul>
<li>Connect a lot of different frontends</li>
<li>Connect a lot of different backends</li>
<li>The middle service can use GraphQL to combine responses from different backends</li>
</ul>
<h2 id="contract-first-design-approach"><a class="header" href="#contract-first-design-approach">Contract First Design Approach</a></h2>
<p>Contract</p>
<ul>
<li>GraphQL =&gt; the Schema</li>
<li>gRPC =&gt; protobuf</li>
<li>REST =&gt;  RAML, Swagger (OpenAPI)</li>
</ul>
<p>APP</p>
<ul>
<li>mock against the contract</li>
</ul>
<p>API</p>
<ul>
<li>mock against the contract</li>
</ul>
<p>Product</p>
<ul>
<li>Merge the APP and API</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="websocket-vs-http2"><a class="header" href="#websocket-vs-http2">Websocket vs. HTTP/2</a></h1>
<p>https://www.infoq.com/articles/websocket-and-http2-coexist/</p>
<div class="table-wrapper"><table><thead><tr><th></th><th>HTTP/2</th><th>WebSocket</th></tr></thead><tbody>
<tr><td>Header</td><td>Compressed (HPACK)</td><td>None</td></tr>
<tr><td>Binary</td><td>YES</td><td>Binary or Textual</td></tr>
<tr><td>Multiplexing</td><td>YES</td><td>YES</td></tr>
<tr><td>Prioritization</td><td>YES</td><td>NO</td></tr>
<tr><td>Compression</td><td>YES</td><td>YES</td></tr>
<tr><td>Direction</td><td>Client/Server + Server Push</td><td>Bidirectional</td></tr>
<tr><td>Full-Duplex</td><td>YES</td><td>YES</td></tr>
</tbody></table>
</div>
<h2 id="is-http2-a-replacement-for-push-technologies-such-as-websocket-or-sse-no"><a class="header" href="#is-http2-a-replacement-for-push-technologies-such-as-websocket-or-sse-no">is HTTP/2 a replacement for push technologies such as WebSocket or SSE? NO</a></h2>
<p>Server Push vs Websocket Bidirectional communication</p>
<ul>
<li>Server push only push data down to the client cache</li>
<li>i.e. the client application does not get notification for the event</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="example"><a class="header" href="#example">Example</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="netflix-zuul-push"><a class="header" href="#netflix-zuul-push">Netflix Zuul Push</a></h1>
<h2 id="zuul-push-architecture"><a class="header" href="#zuul-push-architecture">Zuul Push Architecture</a></h2>
<p>Zuul Push is the push engine at Netflix</p>
<p><img src="system_design/examples/./images/netflix_zuul_000.png" alt="Zuul architecture" /></p>
<h3 id="workflow"><a class="header" href="#workflow">Workflow</a></h3>
<ol>
<li><strong>Client</strong> establishes an persistent websocket/SSE connection to the <strong>Zuul Push Service</strong>. The <strong>Client</strong> will keep the connection alive until the session is terminated.</li>
<li><strong>Zuul Push Service</strong> register the user and connection information to the <strong>Push Registry</strong> database.</li>
<li><strong>Service</strong> that need to send a push message (source of push message) use the <strong>Push Library</strong> (SDK) to send the message to the <strong>Push Message Queue</strong>.</li>
<li><strong>Message Processor</strong>
<ol>
<li>pulls/retrieves an message from the <strong>Push Message Queue</strong></li>
<li>lookups the <strong>Push Registry</strong> to check which <strong>Zuul Push Service</strong> host is connected to the client</li>
<li>delivers the message to the <strong>Zuul Push Service</strong> host</li>
</ol>
</li>
<li><strong>Zuul Push Service</strong> host send the message to the <strong>Client</strong></li>
</ol>
<h2 id="background"><a class="header" href="#background">Background</a></h2>
<p>Netflix use a recommendation engine to generate suggested videos for each user. i.e. the home page of the Netflix website for each user is different.</p>
<p><strong>Push vs Pull</strong></p>
<ul>
<li>Pull
<ul>
<li>If too frequent - Overload the system</li>
<li>If too infrequent - Data not fresh enough</li>
</ul>
</li>
<li>Push
<ul>
<li>Most suited for Netflix</li>
</ul>
</li>
</ul>
<p><strong>Push</strong></p>
<p>Define Push:</p>
<ul>
<li><strong>P</strong>ersist</li>
<li><strong>U</strong>ntil</li>
<li><strong>S</strong>omething</li>
<li><strong>H</strong>appens</li>
</ul>
<p>The server push the data to the client instead of the client requests the data from the server.</p>
<h3 id="zuul-push-servers"><a class="header" href="#zuul-push-servers">Zuul push servers</a></h3>
<p>Handling millions of persistent connections</p>
<p>Using Non-blocking async-io</p>
<p>C10K challengingL</p>
<ul>
<li>Supporting 10K concurrent connection on a single server</li>
</ul>
<p><strong>Traditional method:</strong></p>
<ul>
<li>1 Connection per Socket</li>
<li>1 Socket per thread</li>
</ul>
<p>Socket --&gt; Read --&gt; Write --&gt; Thread 1
Socket --&gt; Write --&gt; Read --&gt; Thread 2</p>
<p><strong>Async I/O</strong></p>
<p>Socket --&gt; write callback --&gt; single thread --&gt; read callback --&gt; Socket</p>
<p>Netflix use <strong>Netty</strong> for the Async I/O</p>
<h3 id="push-registry"><a class="header" href="#push-registry">Push Registry</a></h3>
<p>Push registry feature checklist (the database used as the push registry should have the following feature):</p>
<ul>
<li>Low read latency</li>
<li>Record expiry (e.g. TTL)</li>
<li>Sharding</li>
<li>Replication</li>
</ul>
<p>TTL -&gt; If the client failed to terminated the connection proactively; the system need to use TTL to remove the registered entry from the Push registry.</p>
<p>Good choice for Push Registry</p>
<ul>
<li>Redis</li>
<li>Cassandra</li>
<li>AWS DynamoDB</li>
</ul>
<p>Netflix use <strong>Dynomite</strong></p>
<p>Dynomite =
+ Redis
+ Auto-sharding
+ Read/Write quorum
+ Cross-region replication</p>
<h3 id="message-processing"><a class="header" href="#message-processing">Message Processing</a></h3>
<p>Message queuing + route delivery</p>
<p>Netflix use <strong>Kafka</strong></p>
<p>Message sender use &quot;FIRE and FORGET&quot; approach:</p>
<ul>
<li>Drop the push message into the queue</li>
<li>Carry on with other tasks</li>
</ul>
<p>Cross-Region Replication</p>
<ul>
<li>Netflix use 3 AWS region</li>
<li>Use AWS Kafka queue replication</li>
</ul>
<p>Queue:</p>
<ul>
<li>Hard to use single queue</li>
<li>Different queues for different priorities</li>
</ul>
<p>Message processor</p>
<ul>
<li>multiple message process in parallel</li>
<li>auto scale based on the number of message in the queue</li>
</ul>
<h3 id="operating-zuul-push"><a class="header" href="#operating-zuul-push">Operating Zuul Push</a></h3>
<p>Different from the Stateless services</p>
<p>Stateful:</p>
<ul>
<li>Persistent connections - long lived statble connection
<ul>
<li>Great for client efficiency</li>
<li>Terrible for quick deploy/rollback</li>
</ul>
</li>
</ul>
<p>Deploy/Rollback</p>
<ul>
<li>Client are not automatically migrate to the newly deployed servers</li>
<li><strong>Thundering herd</strong>: If keep the connection at once, the client would try to connect to the new servers at once (overwhelm the servers)</li>
</ul>
<p>Solution:</p>
<ul>
<li>tear down connection periodically (from the server side)</li>
<li>randomize each connection's lifetime (jitter)</li>
<li>result: randomizing connection lifetime on reconnect peak</li>
<li>Extra: server ask client to close its connection (the party terminate the TCP connection might have a FD on linux remain open for up to 2 mins)</li>
</ul>
<h3 id="optimization"><a class="header" href="#optimization">Optimization</a></h3>
<h4 id="how-to-optimize-push-server-most-connection-are-idle"><a class="header" href="#how-to-optimize-push-server-most-connection-are-idle">How to optimize push server? (most connection are idle)?</a></h4>
<p>first approach: big ec2</p>
<ul>
<li>big EC2, as many connection on the single server as possible</li>
<li>Issue: if a server is down: <strong>Thundering herd</strong> happends</li>
</ul>
<p>second approach: goldilocks strategy (just right)</p>
<ul>
<li>m4.large (2v CPU)</li>
<li>84,000 concurrent connection per ec2</li>
</ul>
<p>Optimize for cost, NOT for instance count</p>
<h4 id="how-to-auto-scale-"><a class="header" href="#how-to-auto-scale-">How to auto-scale ?</a></h4>
<p>RPS (request per second) ? NO</p>
<ul>
<li>No RPS for push servers</li>
</ul>
<p>CPU ? NO</p>
<ul>
<li>Instances is not limited by CPU</li>
</ul>
<p>Open Connection ? YES</p>
<ul>
<li>Only factor that is important to a push server</li>
</ul>
<h4 id="aws-elastic-load-balancer-cannot-proxy-websocket"><a class="header" href="#aws-elastic-load-balancer-cannot-proxy-websocket">AWS Elastic Load Balancer cannot proxy WebSocket</a></h4>
<p>ELB does not understand websocket  Upgrade request (A special HTTP request)</p>
<p>Solution: Run ELB as a TCP load balancer (NLB) (Layer 4)</p>
<p>AWS ALB not support WebSocket</p>
<h2 id="use-case-for-push-system"><a class="header" href="#use-case-for-push-system">Use case for Push System</a></h2>
<ul>
<li>On-demand diagnostics
<ul>
<li>Send special diagnostics to devises</li>
</ul>
</li>
<li>Remote recovery</li>
<li>User messaging</li>
</ul>
<h2 id="references-1"><a class="header" href="#references-1">References</a></h2>
<ul>
<li>Susheel Aroskar- <a href="https://www.youtube.com/watch?v=6w6E_B55p0E"><em>Scaling Push Messaging for Millions of Devices @Netflix</em></a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="aws-fargate"><a class="header" href="#aws-fargate">AWS Fargate</a></h1>
<p><img src="system_design/examples/./images/Note-Fargate.png" alt="Fargate" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="questions"><a class="header" href="#questions">Questions</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="design-key-value-store"><a class="header" href="#design-key-value-store">Design Key-Value Store</a></h1>
<p>theorem</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="design-a-rate-limiter"><a class="header" href="#design-a-rate-limiter">Design a Rate Limiter</a></h1>
<h2 id="question-to-ask-1"><a class="header" href="#question-to-ask-1">Question to ask</a></h2>
<ul>
<li>Where is the rate limiter been used?
<ul>
<li>For a gRPC/REST api on the server side?</li>
<li>For a client side - to avoid sending too many request to the server?</li>
<li>For DDoS prevention?</li>
</ul>
</li>
<li>Do we impose a hard limit or a soft limit?
<ul>
<li>Stop serving the request if it hit more than exact 100 QPS?</li>
<li>Or just roughly around 100 QPS?</li>
</ul>
</li>
<li>How do we identify the user?
<ul>
<li>Using IP address?</li>
<li>user account?</li>
<li>AK/SK?</li>
</ul>
</li>
<li>The scale of the system?
<ul>
<li>QPS?</li>
<li>Number of user?</li>
</ul>
</li>
<li>Type of system
<ul>
<li>Distributed system? Monolith?</li>
<li>Single region? Cross-region?</li>
</ul>
</li>
<li>Where is the rate limiter located?
<ul>
<li>A pass-through gateway? Frontend service?</li>
<li>A microservice that determine if a request should be processed?</li>
</ul>
</li>
<li>How do we inform the user?
<ul>
<li>Error code</li>
<li>HTTP Code 429 - Too many</li>
</ul>
</li>
</ul>
<h2 id="off-the-shelf-solution"><a class="header" href="#off-the-shelf-solution">Off the shelf solution</a></h2>
<ul>
<li>AWS: AWS API Gateway - configure throttling for the API</li>
<li>GCP: GCP API Gateway - quota and limits</li>
<li>Azure: Azure API Management - advanced api throttling</li>
</ul>
<h2 id="rate-limit-algorithms"><a class="header" href="#rate-limit-algorithms">Rate limit algorithms</a></h2>
<ul>
<li>token bucket</li>
<li>leaking bucket</li>
<li>fixed window counter</li>
<li>sliding window log</li>
<li>sliding window counter</li>
</ul>
<h3 id="token-bucket-algorithms-1"><a class="header" href="#token-bucket-algorithms-1">Token Bucket Algorithms</a></h3>
<p>algorithms</p>
<ul>
<li>each user is assigned a pre-defined token bucket</li>
<li>each token bucket has a pre-defined capacity</li>
<li>each token bucket receive a fix-ed amount of token at a pre-defined interval
<ul>
<li>if the amount of token exceed the capacity, it would overflow, so the amount of token in the bucket does not exceed the capacity limitation</li>
</ul>
</li>
<li>when receiving a request, the rate limiter will try to retrieve a token from the bucket
<ul>
<li>if a token exist: proceed to process the request</li>
<li>if the bucket is empty: refuse the request</li>
</ul>
</li>
</ul>
<p>key parameters</p>
<ul>
<li>bucket capacity</li>
<li>refill amount</li>
<li>refill interval</li>
</ul>
<p>pro</p>
<ul>
<li>simple algorithm</li>
<li>allow burst request within the bucket capacity
cos</li>
<li>limited tunability due to limited configurable parameters</li>
</ul>
<h3 id="leaking-bucket-algorithms"><a class="header" href="#leaking-bucket-algorithms">leaking bucket algorithms</a></h3>
<p>algorithms</p>
<ul>
<li>each user is assigned a pre-defined FIFO queue with pre-defined size</li>
<li>request are pulled and processed at a fixed rate</li>
<li>when a request comes in, it would try to insert it into the queue
<ul>
<li>if the queue is full, the request will be rejected</li>
<li>if the queue has room, the request will be stored in the queue to be processed</li>
</ul>
</li>
</ul>
<p>key parameters</p>
<ul>
<li>queue size</li>
<li>rate of processing</li>
</ul>
<p>pro</p>
<ul>
<li>stable process flow due to the fixed rate
con</li>
<li>the queue might rate limit after the burst instead of at the burst</li>
<li>limited tunability due to limited configurable parameters</li>
</ul>
<h3 id="fixed-window-counter-algorithm"><a class="header" href="#fixed-window-counter-algorithm">fixed window counter algorithm</a></h3>
<p>TODO</p>
<h3 id="sliding-window-log-algorithm"><a class="header" href="#sliding-window-log-algorithm">sliding window log algorithm</a></h3>
<p>TODO</p>
<h3 id="sliding-window-counter-algorithm"><a class="header" href="#sliding-window-counter-algorithm">sliding window counter algorithm</a></h3>
<p>TODO</p>
<h2 id="high-level-design"><a class="header" href="#high-level-design">High level design</a></h2>
<p>Where to store the counter/queue/log?</p>
<ul>
<li>not in disk (not local disk, not dynamodb, not mysql)</li>
<li>in memory (local memory, redis, memcached)</li>
</ul>
<p>Data consistency (race condition &amp; )</p>
<ul>
<li>require atomic operation - INCR redis operation</li>
</ul>
<p>synchronization issue</p>
<ul>
<li>more than one rate limiter servers, different server is storing different states</li>
<li>solution:
<ul>
<li>consistent hashing</li>
<li>using a shared data store - redis / memcached</li>
</ul>
</li>
</ul>
<h3 id="todo"><a class="header" href="#todo">TODO???</a></h3>
<ul>
<li>what if we want to rate limit the amount of open gRPC stream / websocket connection ?
<ul>
<li>assuming an user can have 5 stream at a time</li>
<li>reject new connection is there are 5 stream open</li>
</ul>
</li>
</ul>
<h2 id="references-2"><a class="header" href="#references-2">References</a></h2>
<ul>
<li>Alex Xu - <em>System Design Interview - An Insider's Guide</em></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="design-distributed-cache"><a class="header" href="#design-distributed-cache">Design Distributed Cache</a></h1>
<p><img src="system_design/questions/./images/Design-Distributed-Cache.png" alt="Distributed Cache" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="design-payment-networks"><a class="header" href="#design-payment-networks">Design Payment Networks</a></h1>
<p><img src="system_design/questions/./images/Design-Payment-Network.png" alt="Distributed Cache" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="confidence"><a class="header" href="#confidence">Confidence</a></h1>
<ul>
<li>Traits of Confident People
<ul>
<li>Postures: How we look?
<ul>
<li>Smooth gestures</li>
<li>More eye contacts</li>
<li>Gain the command of the room</li>
</ul>
</li>
<li>Time
<ul>
<li>Take my time to do things in my pace</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="career-path"><a class="header" href="#career-path">Career Path</a></h1>
<ul>
<li>Avoid decision/analysis paralysis
<ul>
<li>Do not spend weeks/months to figure out what to do.</li>
<li>Just do it and switch course as needed.</li>
</ul>
</li>
<li>Ignore &quot;follow your passion&quot;
<ul>
<li>Most people don't know what is their &quot;passion&quot;</li>
<li>Hence, the passion can be only discover through doing</li>
</ul>
</li>
<li>Focus on the PEOPLE
<ul>
<li>People are the most important contributor to your success</li>
</ul>
</li>
<li>Access new opportunity
<ul>
<li>Impact</li>
</ul>
</li>
<li>Alignment with the business
<ul>
<li>The value of your work for the business</li>
<li>Impact and be valued</li>
<li>Work on high priority projects</li>
<li>Try to work on the CORE of the business / project</li>
</ul>
</li>
</ul>
<h1 id="imposter-syndrome"><a class="header" href="#imposter-syndrome">Imposter Syndrome</a></h1>
<ul>
<li>Accept imposter syndrome</li>
<li>Problem solving
<ul>
<li>Decompose the problem and get started</li>
<li>Keep a job diary and track how you spend your time</li>
</ul>
</li>
<li>Asking questions
<ul>
<li>Asking &gt; being stuck</li>
<li>do not spend more than 15/30 mins been stuck</li>
<li>articulating the questions helps you learn - write it down</li>
<li>build social capital if done correctly</li>
</ul>
</li>
<li>Ramping up on a new team
<ul>
<li>career cold-start algorithm
<ul>
<li>Find someone on the team and meet them for 30 mins</li>
<li>Asks them for a brain dump of
<ol>
<li>what they do?</li>
<li>biggest challenges</li>
<li>who else to meet</li>
</ol>
</li>
<li>repeat the above process until the same names start coming up in num 3</li>
</ul>
</li>
</ul>
</li>
<li>Get high-quality feedback
<ul>
<li>ambiguity causes anxiety</li>
<li>schedule dedicated 1:1s for feedback, ask questions which force deeper reflections - with mgr and techlead - ask deeper questions
<ul>
<li>e.g. last week during the xxx meeting, i does not feel well and dont know how to contribute. what suggestion/feedback do you have on that specific meeting</li>
</ul>
</li>
<li>in code reviews, proactively identify areas where you have concerns or questions</li>
</ul>
</li>
<li>Helping others
<ul>
<li>Create a friendly environment: encourage questions</li>
</ul>
</li>
<li></li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->

        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </body>
</html>
